{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 1: Optimize lepton selection\n",
    "\n",
    "* First, print the distributions of the relevant variables for *all* the Monte Carlo samples (i.e. all the *channels* of the $Z$-boson decay to be studied). Which variables are these? Give sensible ranges to include all the events in the samples (both MC and OPAL data) \n",
    "* Do the same for **one** of the OPAL data samples (your lab assistant will decide which one you choose).\n",
    "* Describe the results.\n",
    "* Optimize the object selection by applying cuts. Make a strategy on how to proceed to find the optimal selection. which information do you need? in thin the\n",
    "* Determine the efficiency and the amount of background for each $Z$ decay channel. Use the simulated events $e^+e^-$, $\\mu^+\\mu^-$, $\\tau^+\\tau^-$ and hadrons ($qq$). Represent the result in a matrix form and think carefully about how you have to correct the measured rates. Don't forget to calculate the errors!\n",
    "* How do we estimate the statistical fluctuations per bin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "### Download libraries\n",
    "%pip install --upgrade pip\n",
    "%pip install uproot \n",
    "%pip install awkward \n",
    "%pip install mplhep \n",
    "%pip install numpy \n",
    "%pip install matplotlib \n",
    "%pip install scipy\n",
    "\n",
    "### Upgrade libraries to latest version\n",
    "%pip install uproot awkward mplhep numpy matplotlib scipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import mplhep\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "path_mc_data = '../../opal_data/mc/'\n",
    "path_data = '../../opal_data/data/'\n",
    "path_lumi_data = '../../opal_data/lumi_files/'\n",
    "ttree_name = 'myTTree'\n",
    "\n",
    "\n",
    "files =[]\n",
    "for file_name in [\"ee\", \"mm\", \"tt\", \"qq\"]:\n",
    "    file = uproot.open(path_mc_data+file_name+'.root')\n",
    "    files.append(file)\n",
    "\n",
    "data_file = uproot.open(path_data+'daten_2.root')\n",
    "lumi_file = path_lumi_data+'daten_2.lum'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "| Variable name | Description |\n",
    "| --- | --- | \n",
    "| <pre>run</pre> | Run number |\n",
    "| <pre>event</pre> | Event number |\n",
    "| <pre>Ncharged</pre> | Number of charged tracks |\n",
    "| <pre>Pcharged</pre> | Total scalar sum of track momenta |\n",
    "| <pre>E_ecal</pre> | Total energy measured in the electromagnetic calorimeter |\n",
    "| <pre>E_hcal</pre> | Total energy measured in the hadronic calorimete |\n",
    "| <pre>E_lep</pre> | LEP beam energy (=$\\sqrt{s}/2$) |\n",
    "| <pre>cos_thru</pre> | cosine of the polar angle between beam axis and thrust axis |\n",
    "| <pre>cos_thet</pre> | cosine of the polar angle between incoming positron and outgoing positive particle |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "ee_cut_params = [\n",
    "         ['Ncharged', \"=\" , 2],\n",
    "         ['E_ecal', \">=\" , 80],\n",
    "    \n",
    "         ['Pcharged', \"<\", 200],\n",
    "         ['Pcharged', \">\", 0],\n",
    "         ['cos_thru', \"<=\", 1],\n",
    "         ['cos_thet', \"<=\", 1, \"ee SR\"],\n",
    "        ]\n",
    "\n",
    "mm_cut_params = [\n",
    "         ['Ncharged', \"=\" , 2],\n",
    "         ['E_ecal', \"<=\" , 40],\n",
    "    \n",
    "         ['Pcharged', \"<\", 200],\n",
    "         ['Pcharged', \">\", 72],\n",
    "\n",
    "         ['cos_thru', \"<=\", 1],\n",
    "         ['cos_thet', \"<=\", 1, \"mm SR\"],\n",
    "        ]\n",
    "\n",
    "tt_cut_params = [\n",
    "         ['Ncharged', \">=\" , 2],\n",
    "         ['Ncharged', \"<=\" , 6],\n",
    "         ['E_ecal', \"<=\" , 70],\n",
    "         \n",
    "         ['Pcharged', \"<\", 200], #for cutflow\n",
    "         ['Pcharged', \"<\", 60],\n",
    "         ['cos_thru', \"<=\", 1],  #for cutflow\n",
    "         ['cos_thru', \"<\", 0.92],\n",
    "         ['cos_thru', \">\", -0.92],\n",
    "\n",
    "         ['Pcharged', \">\", 0, \"tt SR\"],\n",
    "         \n",
    "        ]\n",
    "\n",
    "qq_cut_params = [\n",
    "         ['Ncharged', \">\" , 8],\n",
    "\n",
    "         ['Pcharged', \"<\", 200],\n",
    "         ['Pcharged', \">\", 0],\n",
    "         ['cos_thru', \"<=\", 1, \"qq SR\"],\n",
    "        ]\n",
    "\n",
    "energy_cut_params = [[['E_lep', \"<\" , 88.965/2]],\n",
    "                     [['E_lep', \">\" , 88.965/2],['E_lep', \"<\" , 89.84/2]],\n",
    "                     [['E_lep', \">\" , 89.84/2], ['E_lep', \"<\" , 90.72/2]],\n",
    "                     [['E_lep', \">\" , 90.72/2], ['E_lep', \"<\" , 91.595/2]],\n",
    "                     [['E_lep', \">\" , 91.595/2],['E_lep', \"<\" , 92.465/2]],\n",
    "                     [['E_lep', \">\" , 92.465/2],['E_lep', \"<\" , 93.36/2]],\n",
    "                     [['E_lep', \">\" , 93.36/2]],\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "nf_s = []\n",
    "nf_s_err = []\n",
    "\n",
    "def plot_hist(mc_data, binning, data=None, title=\"\", xlabel=\"\", ylabel='Events', cut_text=\"\",\n",
    "              log=False, nf_applied=True,\n",
    "              fnc=None):\n",
    "     \n",
    "    minval = min([min(data_row) if len(data_row) > 0  else 0 for data_row in mc_data])\n",
    "    maxval = max([max(data_row) if len(data_row) > 0  else 0 for data_row in mc_data])\n",
    "    \n",
    "    print(minval, maxval)\n",
    "    \n",
    "    if binning == \"int\":\n",
    "        binning = 1#range(0, int(maxval)+1)\n",
    "        \n",
    "    if data is not None:\n",
    "        fig, axs = plt.subplots(2,1,figsize=(16,9), sharex=True, gridspec_kw={'height_ratios': [3, 1]})    \n",
    "    else:\n",
    "#         fig, axs = plt.subplots(1,1,figsize=(16,9))    \n",
    "        axs = [plt]\n",
    "\n",
    "    if nf_applied:\n",
    "        axs[0].plot([], [], 'none', zorder=-10, label=\"nfs applied\")\n",
    "    \n",
    "    label=[\"ee\", \"mm\", \"tt\", \"qq\"]\n",
    "    mc_bin_content_list = []\n",
    "    for i,mc_data_channel in enumerate(mc_data):\n",
    "        mc_bin_content, mc_bin_edges = np.histogram(\n",
    "            mc_data_channel, bins=np.arange(minval, maxval+binning, binning)) \n",
    "        if nf_applied:\n",
    "            mc_bin_content = mc_bin_content * nf_s[i]\n",
    "        if len(mc_bin_content_list) > 0:\n",
    "            mc_bin_content += mc_bin_content_list[-1]\n",
    "        mc_bin_content_list.append(mc_bin_content)\n",
    "    \n",
    "        mc_x = 0.5*(mc_bin_edges[1:] + mc_bin_edges[:-1])\n",
    "    for i in range(4):  \n",
    "        axs[0].bar(mc_x, mc_bin_content_list[i], binning,\n",
    "            label=label[i], zorder=-i)\n",
    "    \n",
    "    mc_bin_content = mc_bin_content_list[-1]\n",
    "    mc_error_sizes = np.sqrt(mc_bin_content)\n",
    "        \n",
    "    axs[0].errorbar(mc_x, mc_bin_content, yerr=mc_error_sizes, \n",
    "                 fmt='none', ecolor=\"grey\", capsize=400/len(mc_x))\n",
    "    \n",
    "    \n",
    "    if data is not None:\n",
    "        data_bin_content, data_bin_edges = np.histogram(\n",
    "            data, bins=np.arange(minval, maxval+binning, binning))\n",
    "\n",
    "        data_x = 0.5*(data_bin_edges[1:] + data_bin_edges[:-1])\n",
    "\n",
    "        data_bin_content = data_bin_content\n",
    "        data_error_sizes = np.sqrt(data_bin_content)\n",
    "        \n",
    "        axs[0].plot(data_x, data_bin_content, 'ko', label=\"data\")\n",
    "        axs[0].errorbar(data_x, data_bin_content, yerr=data_error_sizes, \n",
    "                     fmt='none', ecolor=\"k\")\n",
    "        \n",
    "        axs[1].plot(data_x, data_bin_content/mc_bin_content, \n",
    "                    'ko', label=\"data\")\n",
    "        axs[1].errorbar(data_x, data_bin_content/mc_bin_content, \n",
    "                        yerr=data_error_sizes/mc_bin_content, fmt='none', ecolor=\"k\")\n",
    "        axs[1].set_ylim([0.5,1.5])\n",
    "        axs[1].set_ylabel(\"data / MC\")\n",
    "        axs[1].grid()\n",
    "        \n",
    "    if fnc:\n",
    "        fnc(axs[0], data_x, data_bin_content, data_error_sizes)\n",
    "\n",
    "    axs[0].legend()\n",
    "    if log:\n",
    "        axs[0].yscale('log')\n",
    "    axs[0].set_title(title)\n",
    "    axs[0].set_ylabel(ylabel)\n",
    "    axs[-1].set_xlabel(xlabel)\n",
    "    fig.text(0.1, 0, cut_text)\n",
    "        \n",
    "    plt.savefig(\"plots/{}.png\".format(title))\n",
    "    plt.show()\n",
    "\n",
    "def load_variable(variable, branches):\n",
    "    data_row = None\n",
    "    if variable == \"E_ecal+hcal\":\n",
    "        data_row = ak.to_numpy(branches[\"E_ecal\"]) +  ak.to_numpy(branches[\"E_hcal\"])\n",
    "    else:\n",
    "        data_row = ak.to_numpy(branches[variable])\n",
    "\n",
    "    label = \"?\"\n",
    "    if variable == \"Ncharged\": label = r\"$n_{tracks}$\"\n",
    "    elif variable == \"Pcharged\": label = r\"$p_{charged}$ [GeV]\"\n",
    "    elif variable == \"E_ecal\": label = r\"$E_{ecal}$ [GeV]\"\n",
    "    elif variable == \"E_hcal\": label = r\"$E_{hcal}$ [GeV]\"\n",
    "    elif variable == \"E_lep\": label = r\"$\\sqrt{s} / 2$ [GeV]\"\n",
    "    elif variable == \"cos_thru\": label = r\"$cos(\\theta_{thrust}$)\"\n",
    "    elif variable == \"cos_thet\": label = r\"$cos(\\theta)$\"\n",
    "\n",
    "    return data_row, label\n",
    "\n",
    "def calculate_cuts(cuts, files):\n",
    "    final_cut_mask = [[]]*len(files)\n",
    "\n",
    "    for i,file in enumerate(files):\n",
    "\n",
    "        branches = file[ttree_name].arrays()\n",
    "\n",
    "        cut_masks = []\n",
    "\n",
    "        for cut in cuts:\n",
    "            cut_var = cut[0]\n",
    "            cut_logic = cut[1]\n",
    "            cut_val = cut[2]\n",
    "\n",
    "            data_row,_ = load_variable(cut_var, branches)\n",
    "\n",
    "            cut_mask = []\n",
    "            if cut_logic == \">\":\n",
    "                cut_mask = np.array(data_row > cut_val)\n",
    "            elif cut_logic == \">=\":\n",
    "                cut_mask = np.array(data_row >= cut_val)\n",
    "            elif cut_logic == \"=\":\n",
    "                cut_mask = np.array(data_row == cut_val)\n",
    "            elif cut_logic == \"<=\":\n",
    "                cut_mask = np.array(data_row <= cut_val)\n",
    "            elif cut_logic == \"<\":\n",
    "                cut_mask = np.array(data_row < cut_val)\n",
    "            elif cut_logic == \"><\":\n",
    "                cut_mask = np.array(data_row < cut_val[0]) | np.array(data_row > cut_val[1])\n",
    "\n",
    "            cut_masks.append(cut_mask)\n",
    "\n",
    "        final_cut_mask[i] = [True] * len(branches)\n",
    "\n",
    "\n",
    "        for cut_mask in cut_masks:\n",
    "            final_cut_mask[i] = final_cut_mask[i] & cut_mask\n",
    "\n",
    "    return final_cut_mask\n",
    "\n",
    "def create_curflow(cuts, files):\n",
    "    \n",
    "    temp_cuts = []\n",
    "    for cut in cuts:\n",
    "        temp_cuts.append(cut)\n",
    "        \n",
    "        cut_mask = calculate_cuts(temp_cuts, files)\n",
    "        eff_list = []\n",
    "        for i in range(4):\n",
    "            eff = sum(cut_mask[i]) / len(cut_mask[i])\n",
    "            eff_list.append(eff)\n",
    "        print(cut, eff_list)\n",
    "        \n",
    "def plot_cut_hists(cuts, binning):\n",
    "    \n",
    "    temp_cuts = []\n",
    "    for i,cut in enumerate(cuts):\n",
    "        \n",
    "        if i < len(binning) and binning[i]:\n",
    "            print(\"before\", cut)\n",
    "            plot_hist_with_cuts(temp_cuts, [[cut[0], binning[i]]], log=False)\n",
    "        \n",
    "        temp_cuts.append(cut)\n",
    "        \n",
    "\n",
    "\n",
    "def plot_hist_with_cuts(cuts, hists, log=False, nf_applied=True, plot_data=True, title_mod=\"\", fnc=None):\n",
    "\n",
    "    print(cuts)\n",
    "\n",
    "    mc_cut_mask = calculate_cuts(cuts, files)\n",
    "\n",
    "    data_cut_mask = calculate_cuts(energy_cut_params[3] + cuts, [data_file])\n",
    "\n",
    "        \n",
    "    for hist in hists:\n",
    "        variable, binning = hist\n",
    "        \n",
    "        branches = data_file[ttree_name].arrays()\n",
    "        data_row, _ = load_variable(variable, branches)\n",
    "        data_row = data_row[data_cut_mask[0]]\n",
    "        \n",
    "        mc_data = []\n",
    "\n",
    "        for i,file in enumerate(files):\n",
    "\n",
    "            \n",
    "            \n",
    "            branches = file[ttree_name].arrays()\n",
    "            mc_data_row, label = load_variable(variable, branches)\n",
    "            mc_data_row = mc_data_row[mc_cut_mask[i]]\n",
    "\n",
    "            mc_data.append(mc_data_row)\n",
    "\n",
    "        title = \"\"\n",
    "        if len(cuts)>0:\n",
    "            final_cut = cuts[-1]\n",
    "            if len(final_cut) >= 4:\n",
    "                title=\"{}: '{}'\".format(final_cut[3],variable)\n",
    "            else:\n",
    "                title=\"'{}' {} {} cut: '{}'\".format(*final_cut,variable)\n",
    "        else:\n",
    "                title=\"without cuts: '{}'\".format(variable)    \n",
    "        \n",
    "        cut_text = \"applied cuts: \"\n",
    "        for cut in cuts:\n",
    "            if len(cut) >= 4:\n",
    "                cut_text +=\"'{}' {} {} ({}); \".format(*cut)\n",
    "            else:\n",
    "                cut_text +=\"'{}' {} {}; \".format(*cut)\n",
    "\n",
    "                \n",
    "        plot_hist(mc_data, binning, data=data_row if plot_data else None, \n",
    "                  title=title+title_mod, xlabel=label, cut_text=cut_text,\n",
    "                  log=log, nf_applied=nf_applied, fnc=fnc)\n",
    "\n",
    "for j,sr_cuts in enumerate([ee_cut_params, mm_cut_params, tt_cut_params, qq_cut_params]):\n",
    "\n",
    "    mc_cut_mask = calculate_cuts(sr_cuts, files)\n",
    "    data_cut_mask = calculate_cuts(energy_cut_params[3] + sr_cuts, [data_file])\n",
    "    \n",
    "    mc_events = sum(sum(c) for c in mc_cut_mask)\n",
    "    data_events = sum(sum(c) for c in data_cut_mask)\n",
    "    nf = data_events / mc_events\n",
    "    nf_err = np.sqrt((np.sqrt(data_events)/mc_events)**2 +\\\n",
    "                     (np.sqrt(mc_events)*data_events/mc_events**2)**2)\n",
    "    print(\"nf{}: {} +- {}\".format(j,nf,nf_err))\n",
    "    nf_s.append(nf)\n",
    "    nf_s_err.append(nf_err)\n",
    "\n",
    "# plot_hist_with_cuts(ee_cut_params,[[\"cos_thet\", .01]])\n",
    "plot_hist_with_cuts([['Pcharged', \">\", 0],   \n",
    "                     ['Pcharged', \"<\", 200], \n",
    "                     ['cos_thru', \"<=\", 1]],[[\"Pcharged\", 5]])\n",
    "plot_hist_with_cuts(ee_cut_params,[[\"E_hcal\", 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "## Define an numpy array for 'Pcharged'\n",
    "var = 'E_lep'\n",
    "data = []\n",
    "for file in files:\n",
    "    branches = file[ttree_name].arrays()\n",
    "\n",
    "    data_row = ak.to_numpy(branches[var]) # See Docu (https://awkward-array.org/how-to-convert-numpy.html) for more conversions\n",
    "    data.append(data_row)\n",
    "    print(var, len(data_row), data_row*2)\n",
    "\n",
    "# plt.hist(data, stacked=True, bins=range(0,int(max(data[3]))+1),\n",
    "#          label=[\"ee\", \"mm\", \"tt\", \"qq\"])\n",
    "# plt.legend()\n",
    "# # plt.yscale('log')\n",
    "# plt.show()\n",
    "\n",
    "plot_hist_with_cuts([\n",
    "        ['Pcharged', \">\", 0],         \n",
    "        ['Pcharged', \"<\", 200],     \n",
    "        ['cos_thru', \"<=\", 1],\n",
    "#         ['cos_thet', \"<=\", 1],\n",
    "    ], [[\"Ncharged\", \"int\"], [\"Pcharged\", 5],[\"E_ecal+hcal\", 5],[\"E_ecal\", 5],[\"E_hcal\", 5], [\"cos_thru\", .02]])\n",
    "\n",
    "plot_hist_with_cuts([\n",
    "        ['Pcharged', \">\", 0],         \n",
    "        ['Pcharged', \"<\", 200],     \n",
    "        ['cos_thru', \"<=\", 1],\n",
    "        ['cos_thet', \"<=\", 1],\n",
    "    ], [[\"cos_thet\", .02]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "category = 0\n",
    "\n",
    "branches =  files[category][ttree_name].arrays()\n",
    "\n",
    "cut_mask = calculate_cuts([\n",
    "        [\"Pcharged\", \">\", 0],\n",
    "        [\"Pcharged\", \"<=\", 200],\n",
    "        [\"cos_thet\", \"<=\", 1]\n",
    "    ], [files[category]])\n",
    "\n",
    "#print(cut_mask)\n",
    "\n",
    "datax = ak.to_numpy(branches[\"E_ecal\"])[cut_mask[0]]\n",
    "datay = ak.to_numpy(branches[\"cos_thet\"])[cut_mask[0]]\n",
    "\n",
    "plt.hist2d(datax, datay, bins=100, range=None, density=False, weights=None, cmin=None, cmax=None,  data=None)\n",
    "title = \"E_ecal and cos_thet\"\n",
    "plt.title(title)\n",
    "plt.xlabel(r\"$E_{ecal} [GeV]$\")\n",
    "plt.ylabel(r\"$cos(\\theta)$\")\n",
    "\n",
    "plt.savefig(\"plots/{}.png\".format(title))\n",
    "plt.show()\n",
    "\n",
    "datax = ak.to_numpy(branches[\"Pcharged\"])[cut_mask[0]]\n",
    "datay = ak.to_numpy(branches[\"cos_thet\"])[cut_mask[0]]\n",
    "\n",
    "plt.hist2d(datax, datay, bins=100, range=None, density=False, weights=None, cmin=None, cmax=None,  data=None)\n",
    "title = \"Pcharged and cos_thet\"\n",
    "plt.title(title)\n",
    "plt.xlabel(r\"$P_{charged} [GeV]$\")\n",
    "plt.ylabel(r\"$cos(\\theta)$\")\n",
    "\n",
    "plt.savefig(\"plots/{}.png\".format(title))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print(\"ee with n_track = 0\")\n",
    "plot_hist_with_cuts([\n",
    "         \n",
    "         #['E_ecal', \">=\" , 80],\n",
    "\n",
    "         #['Pcharged', \">\", 0],\n",
    "         #['Pcharged', \"<\", 200],\n",
    "         ['cos_thru', \"<=\", 1],\n",
    "         ['cos_thet', \"<=\", 1],\n",
    "         ['Ncharged', \"=\" , 0],\n",
    "        ], [[\"cos_thet\", .02]])\n",
    "\n",
    "print(\"ee\")\n",
    "plot_cut_hists(ee_cut_params, [\"int\", 5])\n",
    "\n",
    "plot_hist_with_cuts(ee_cut_params, [[\"Pcharged\",5],[\"E_ecal\", 5],[\"E_hcal\", 5], [\"cos_thru\", .02], [\"cos_thet\", .02]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print(\"mm\")\n",
    "plot_cut_hists(mm_cut_params, [\"int\", 5, None, 5])\n",
    "\n",
    "plot_hist_with_cuts(mm_cut_params, [[\"Pcharged\", 5],[\"E_ecal\", 5], [\"E_hcal\", 5], [\"cos_thru\", .04], [\"cos_thet\", .04]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print(\"tt\")\n",
    "plot_cut_hists(tt_cut_params, [\"int\", None, 5, None, 5, None, 0.04])\n",
    "\n",
    "plot_hist_with_cuts(tt_cut_params, \n",
    "                    [[\"Pcharged\",5],\n",
    "                     [\"E_ecal\", 5],                                     \n",
    "                     [\"E_hcal\", 5], \n",
    "                     [\"cos_thru\", .04],                                     \n",
    "                     #[\"cos_thet\", 100]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print(\"qq\")\n",
    "plot_cut_hists(qq_cut_params, [\"int\"])\n",
    "\n",
    "plot_hist_with_cuts(qq_cut_params, [[\"Pcharged\", 5],[\"E_ecal+hcal\", 5],[\"E_ecal\", 5],[\"E_hcal\", 5], [\"cos_thru\", .02]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Think about the statistical uncertainties computed above in 'error_sizes'. \n",
    "* **Are these sensible? Why do we use this formula?** (Hint: Making an histogram is, in short, a *counting experiment*. In the limit of large total number of events, the (binomial) probability function limits to the *Poisson distribution*. What is the variance? And the standard deviation?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Matrix Inversion\n",
    "To determine the uncertainties of the matrix elements after the inversion we use Monte Carlo toy experiments. In this context, what are the advantages and disadvantages of this method when compared to analytical expressions? Discuss it briefly.\n",
    "\n",
    "**References**:\n",
    "* Propagation of Errors for Matrix Inversion: https://arxiv.org/abs/hep-ex/9909031v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 2: Separate $t$- and $s$-channel contributions\n",
    "\n",
    "Only Feynman diagrams contributing to the production of $Z$ boson are to be considered for the measurements. The **electron** Monte Carlo sample incorporate contributions from $t$- and $s$-channels.\n",
    "* Select/correct contributions producing $Z$ boson decays. (Hint: Which role does the $\\cos(\\theta)$ distribution play in separating $t$- and $s$-channels?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "fit_results = []\n",
    "\n",
    "def create_fit(ax, data_x, data_bin_content, data_error_sizes):\n",
    "    \n",
    "    mask = np.array(data_x > -.76) & np.array(data_x < .76) \\\n",
    "#     & (np.array(x < .78) | np.array(x > .81)) \\\n",
    "#     & (np.array(x > -.78) | np.array(x < -.81))\n",
    "\n",
    "\n",
    "    data_x = data_x[mask]\n",
    "    data_bin_content = data_bin_content[mask]\n",
    "    data_error_sizes = data_error_sizes[mask]\n",
    "\n",
    "    ax.plot(data_x, data_x*0+10, 'bx', label=\"bins used for fit\")\n",
    "\n",
    "\n",
    "    # Define model function to be used to fit to the data above:\n",
    "    def fit(x, A, B):\n",
    "        return A*(1+ x**2)+B*(1-x)**(-2) #+ C\n",
    "\n",
    "\n",
    "    # p0 is the initial guess for the fitting coefficients (A, mu and sigma above)\n",
    "    p0 = [100,0]\n",
    "\n",
    "    # ## Fit curve (WARNING: The fit does not propagate bin uncertainties to the uncertainties of the fit parameters!)\n",
    "    coeff, var_matrix = curve_fit(fit, data_x, data_bin_content, p0=p0, sigma=data_error_sizes)\n",
    "    coeff_err = np.sqrt(np.diag(var_matrix))\n",
    "\n",
    "\n",
    "#     ax.plot(data_x, fit(data_x, *p0), \"g--\",label='Guess')\n",
    "\n",
    "    ax.plot(data_x, fit(data_x, *coeff), \"r--\", label= \\\n",
    "             r\"Fit $A \\cdot(1 + cos^2(\\theta))+ B \\cdot \\left(\\frac{1}{(1 - cos(\\theta))^2}\\right)$\")\n",
    "\n",
    "    ax.plot([],[], 'none', label=r\"\"\"\n",
    "    A = ${0:f} \\pm {2:f}$\n",
    "    B = ${1:f} \\pm {3:f}$\n",
    "    \"\"\".format(*coeff, *coeff_err))\n",
    "    #---------------\n",
    "\n",
    "    print(*coeff,*coeff_err)\n",
    "    fit_results.append([*coeff, *coeff_err])\n",
    "\n",
    "plot_hist_with_cuts(ee_cut_params, [[\"cos_thet\", .04]], title_mod=\" fit\", fnc=create_fit)\n",
    "print(fit_results)\n",
    "a, b, a_err, b_err = fit_results[0]\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "matrix = []\n",
    "matrix_err = []\n",
    "purity_list = []\n",
    "purity_err_list = []\n",
    "\n",
    "\n",
    "for j,sr_cuts in enumerate([ee_cut_params, mm_cut_params, tt_cut_params, qq_cut_params]):\n",
    "    \n",
    "    print(sr_cuts)\n",
    "#     create_curflow(sr_cuts, files)\n",
    "#     print()\n",
    "    \n",
    "    cut_mask = calculate_cuts(sr_cuts, files)\n",
    "    \n",
    "    events_SR = sum(sum(c) for c in cut_mask)\n",
    "    events_SR_channels = [sum(c) for c in cut_mask]\n",
    "    purity_list.append(events_SR_channels[j]/events_SR)\n",
    "    purity_err_list.append(np.sqrt(events_SR_channels[j])/events_SR \\\n",
    "                           + events_SR_channels[j]/events_SR**2 * np.sqrt(events_SR))\n",
    "    \n",
    "    eff_list = []\n",
    "    eff_err_list = []\n",
    "    for i in range(4):\n",
    "#         print(sum(cut_mask[i]))\n",
    "        eff = sum(cut_mask[i]) / 10**5\n",
    "        eff_err = np.sqrt(sum(cut_mask[i])) / 10**5\n",
    "        \n",
    "        if eff_err < 1/10**5:\n",
    "            eff_err = 1/10**5\n",
    "            \n",
    "        if i==0:\n",
    "#             a,b,a_err,b_err = coeff[0], coeff[1], coeff_err[0], coeff_err[1] \n",
    "            eff = eff / (a/(a+b))\n",
    "            A_B_err = np.sqrt((a_err * (b) / a**2)**2 + (b_err / a)**2) \n",
    "            eff_err = np.sqrt((eff_err / (a/(a+b)))**2 + (eff * A_B_err)**2)\n",
    "        \n",
    "        eff_list.append(eff)\n",
    "        eff_err_list.append(eff_err)\n",
    "    matrix.append(eff_list)\n",
    "    matrix_err.append(eff_err_list)\n",
    "\n",
    "matrix = np.array(matrix)\n",
    "matrix_err = np.array(matrix_err)\n",
    "for i in range(4):\n",
    "    fstr = [\"({\"+str(i)+\":f} +- {\"+str(i+4)+\":f}) \" for i in range(4)]\n",
    "    fstr = \"\".join(fstr)\n",
    "\n",
    "    print(fstr.format(*matrix[i], *matrix_err[i]))\n",
    "\n",
    "print(matrix)\n",
    "print(matrix_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "matrix = matrix\n",
    "error_matrix = matrix_err\n",
    "\n",
    "inv = np.linalg.inv(matrix)\n",
    "print(inv)\n",
    "\n",
    "### Number of toy experiments to be done\n",
    "ntoy = 1000\n",
    "\n",
    "### Create numpy matrix of list to append elements of inverted toy matrices\n",
    "inverse_toys = np.empty((4,4))\n",
    "\n",
    "# Create toy efficiency matrix out of gaussian-distributed random values\n",
    "for i in range(0,ntoy,1):\n",
    "    toy_matrix = np.zeros((4,4))\n",
    "    toy_matrix = np.random.normal(matrix,error_matrix,size=(4,4))\n",
    "    \n",
    "    ### Invert toy matrix\n",
    "    inverse_toy = np.linalg.inv(toy_matrix)\n",
    "    \n",
    "    #print(inverse_toys.item(0,0),inverse_toy.item(0,0))\n",
    "    # Append values\n",
    "    inverse_toys = np.dstack((inverse_toys,inverse_toy))\n",
    "    \n",
    "# Define gaussian function to fit to the toy distributions:\n",
    "def gauss(x, A, mu, sigma):\n",
    "    return A*np.exp(-(x-mu)**2/(2.*sigma**2))\n",
    "\n",
    "\n",
    "inverse_errors = np.zeros((4,4))\n",
    "inverse_means = np.zeros((4,4))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10),dpi=80)\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.2)\n",
    "\n",
    "\n",
    "# axes = [[0]*4]*4\n",
    "\n",
    "ax00 = plt.subplot(4,4,1)\n",
    "ax01 = plt.subplot(4,4,2)\n",
    "ax02 = plt.subplot(4,4,3)\n",
    "ax03 = plt.subplot(4,4,4)\n",
    "\n",
    "ax10 = plt.subplot(4,4,5)\n",
    "ax11 = plt.subplot(4,4,6)\n",
    "ax12 = plt.subplot(4,4,7)\n",
    "ax13 = plt.subplot(4,4,8)\n",
    "\n",
    "ax20 = plt.subplot(4,4,9)\n",
    "ax21 = plt.subplot(4,4,10)\n",
    "ax22 = plt.subplot(4,4,11)\n",
    "ax23 = plt.subplot(4,4,12)\n",
    "\n",
    "ax30 = plt.subplot(4,4,13)\n",
    "ax31 = plt.subplot(4,4,14)\n",
    "ax32 = plt.subplot(4,4,15)\n",
    "ax33 = plt.subplot(4,4,16)\n",
    "\n",
    "axes = [[ax00,ax01,ax02,ax03],\n",
    "        [ax10,ax11,ax12,ax13],\n",
    "        [ax20,ax21,ax22,ax23],\n",
    "        [ax30,ax31,ax32,ax33]]\n",
    "\n",
    "\n",
    "## IMPORTANT! Find suitable ranges to fit/plot gaussian distributions successfully!\n",
    "ranges = [[(0.0,1)   ,(-0.02,0.02), (-0.02,0.02), (-0.02,0.02)],\n",
    "          [(-0.02,0.02),(0,1) , (-0.02,0.02), (-0.02,0.02)],\n",
    "          [(-0.02,0.02),(-0.02,0.02), (0,1)   , (-0.02,0.02)],\n",
    "          [(-0.02,0.02),(-0.02,0.02), (-0.02,0.02), (0.85,1.05)]]\n",
    "\n",
    "\n",
    "# Fill histograms for each inverted matrix coefficient:\n",
    "for j in range(0,4,1):\n",
    "    for k in range(0,4,1):\n",
    "        \n",
    "        # Diagonal and off-diagonal terms have different histogram ranges\n",
    "        hbins, hedges, _ = axes[j][k].hist(inverse_toys[j,k,:],bins=30,#range=ranges[j][k],\n",
    "                                           histtype='step', linewidth=2, label=f'toyhist {j} {k}')\n",
    "\n",
    "        ## Guess initial parameters of the fit by taking random value from hist and std\n",
    "        _p0 = [ntoy/10.,np.std(inverse_toys[j,k,:]),np.std(inverse_toys[j,k,:])]\n",
    "\n",
    "        # Get the fitted curve\n",
    "        h_mid = 0.5*(hedges[1:] + hedges[:-1]) #Calculate midpoints for the fit\n",
    "        \n",
    "        max_val,max_index, fwhm = 0,0,0\n",
    "        for i,v in enumerate(hbins):\n",
    "            if v > max_val:\n",
    "                max_val = v\n",
    "                max_index = i\n",
    "        for i in range(max_index, len(hbins)):\n",
    "            if hbins[i] < max_val/2:\n",
    "                fwhm = 2 * (h_mid[i] - h_mid[max_index])\n",
    "            \n",
    "        mu_guess = h_mid[max_index]\n",
    "        guess = [max_val,mu_guess, fwhm*.1]\n",
    "        axes[j][k].plot(h_mid, gauss(h_mid, *guess),label=f'Guess {j} {k}')\n",
    "\n",
    "        try:\n",
    "            coeffs, _ = curve_fit(gauss, h_mid, hbins, p0=guess, maxfev=10000)\n",
    "\n",
    "            axes[j][k].plot(h_mid, gauss(h_mid, *coeffs),label=f'Fit {j} {k}')\n",
    "\n",
    "            inverse_means[j,k] = coeffs[1]\n",
    "            inverse_errors[j,k] = abs(coeffs[2])\n",
    "        except Exception as e:\n",
    "            print(j,k, e)\n",
    "        \n",
    "        axes[j][k].legend()\n",
    "\n",
    "print(f\"Erros for the inverse matrix:\\n{inverse_errors}\")\n",
    "\n",
    "title = \"inverse matrix toy results\"\n",
    "plt.title(title)\n",
    "# plt.xlabel(r\"$P_{charged} [GeV]$\")\n",
    "# plt.ylabel(r\"$cos(\\theta)$\")\n",
    "\n",
    "plt.savefig(\"plots/{}.png\".format(title))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x = []\n",
    "lumi = [[],[],[],[],[]]\n",
    "\n",
    "with open(lumi_file) as csv_file:\n",
    "    \n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    \n",
    "    line_count = 0\n",
    "    column_count = 0\n",
    "    \n",
    "    for row in csv_reader:\n",
    "            if line_count > 0:\n",
    "                x.append(row)\n",
    "                line_count += 1\n",
    "            else:\n",
    "                line_count += 1\n",
    "    \n",
    "    \n",
    "    for column_count in range(5):\n",
    "        \n",
    "        lumi[column_count] = []\n",
    "        \n",
    "        for row_2 in x:\n",
    "            \n",
    "            if line_count > 0:\n",
    "                lumi[column_count].append(float(row_2[column_count]))\n",
    "                line_count += 1\n",
    "            else:\n",
    "                line_count += 1\n",
    "        \n",
    "\n",
    "print(x)\n",
    "print(lumi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x_sec_list = []\n",
    "x_sec_err_tot_list = []\n",
    "x_sec_err_par_list = []\n",
    "\n",
    "xs_corrections = { 'energy' : [ 88.47, 89.46, 90.22, 91.22, 91.97, 92.96, 93.76] ,\n",
    "                      'hadronic' : [2.0, 4.3, 7.7, 10.8, 4.7, -0.2, -1.6],\n",
    "                      'leptonic' : [0.09, 0.20, 0.36, 0.52, 0.22, -0.01, -0.08]}\n",
    "\n",
    "\n",
    "for j in range(7):\n",
    "    s_energy = lumi[0][j]\n",
    "\n",
    "\n",
    "    vec = []\n",
    "    for i,sr_cuts in enumerate([ee_cut_params, mm_cut_params, tt_cut_params, qq_cut_params]):\n",
    "#         create_curflow(sr_cuts, files)\n",
    "\n",
    "        sr_cuts =[*sr_cuts,*energy_cut_params[j]]\n",
    "        \n",
    "        cut_mask = calculate_cuts(sr_cuts, [data_file])\n",
    "        \n",
    "        events_SR = sum(sum(c) for c in cut_mask)\n",
    "        vec.append(events_SR)\n",
    "    vec = np.array(vec)    \n",
    "    result = np.array(np.dot(inv,vec))\n",
    "#     print(result, 1/lumi[1][j])\n",
    "    \n",
    "    x_sec = result / lumi[1][j]\n",
    "    for i in range(3):\n",
    "        x_sec[i] += xs_corrections['leptonic'][j]\n",
    "    x_sec[3] += xs_corrections['hadronic'][j]    \n",
    "    mc_stat_err = np.array([np.dot(inverse_errors[x],result) /lumi[1][j] for x in range(4)])\n",
    "#     print(mc_stat_err)\n",
    "    data_stat_err = np.array([np.dot(inv[x],np.sqrt(vec)) /lumi[1][j] for x in range(4)])\n",
    "#     print(data_stat_err)\n",
    "    lumi_stat_err = result / lumi[1][j]**2 * lumi[2][j]\n",
    "    lumi_sys_err = result / lumi[1][j]**2 * lumi[3][j]\n",
    "    x_sec_err_tot = np.sqrt(mc_stat_err**2 + data_stat_err**2 + lumi_stat_err**2 + lumi_sys_err**2)\n",
    "#     print(x_sec_err_tot)\n",
    "    x_sec_list.append([*x_sec])\n",
    "    x_sec_err_tot_list.append([*x_sec_err_tot])\n",
    "    x_sec_err_par_list_temp = []\n",
    "    for y in range(4):\n",
    "        x_sec_err_par_list_temp.append([mc_stat_err[y],data_stat_err[y],\\\n",
    "                                        lumi_stat_err[y],lumi_sys_err[y]])\n",
    "    x_sec_err_par_list.append(x_sec_err_par_list_temp)\n",
    "    #print(\"xSec of {}GeV: {}\".format(s_energy, x_sec))\n",
    "print(x_sec_list)\n",
    "print(x_sec_err_tot_list)\n",
    "print(x_sec_err_par_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 3: Measurement of the total production cross sections\n",
    "\n",
    "For **each** of the seven centre-of-mass energies:\n",
    "* Determine the number of events in the handronic channel *and* in the three leptonic channels\n",
    "* Substract the background and correct for selection efficiencies accordingly\n",
    "* Then, calculate the differnetial cross sections for the hadronic *and* the leptnic channels\n",
    "* Add the radiation corrections from The table given below. **Don't forget to take the uncertainties (errors) into account!**\n",
    "\n",
    "| $\\sqrt{s}$   \\[GeV\\]| Correction hadronic channel    \\[nb\\] |  Correction leptonic channel   \\[nb\\]|\n",
    "| --- | --- | --- |\n",
    "| 88.47 | +2.0  | +0.09 |\n",
    "| 89.46 | +4.3  | +0.20 |\n",
    "| 90.22 | +7.7  | +0.36 |\n",
    "| 91.22 | +10.8 | +0.52 |\n",
    "| 91.97 | +4.7  | +0.22 |\n",
    "| 92.96 | -0.2  | -0.01 |\n",
    "| 93.76 | -1.6  | -0.08 |\n",
    "\n",
    "Feel free to access these values using the dictionary 'xs_corrections' given below.\n",
    "* Once the total cross section for all four decay channels at all seven energies have been measured, fit a **Breit-Wigner distribution** to measure the $Z$ boson mass ($m_Z$) and the resonance width ($\\Gamma_Z$) and the peak cross section s of the resonance for the hadronic and the leptonic channels. Again, **propagate the uncertainties carefully**.\n",
    "* Compare your results to the OPAL cross section s and the theoretical predictions. How many degrees of freedom does the fit have? How can you udge if the model is compatible with the measured data? Calculate the  **confidence levels**.\n",
    "* Calculate the partial widths for all channels from the measured cross sections on the peak. Which is the best partial width to start with? Compare them with the theoretical predictions and the values that you have calculated in the beginning.\n",
    "* Determine from your results the **number of generations of light neutrinos**. Which assumptions are necessary?\n",
    "* Discuss in detail the systematic uncertainties in the whole procedure of the analysis. Which assumptions were necessary?\n",
    "\n",
    "These are some **references** that might be interesting to look up:\n",
    "* Particle Data Book: https://pdg.lbl.gov/2020/download/Prog.Theor.Exp.Phys.2020.083C01.pdf\n",
    "** Resonances: https://pdg.lbl.gov/2017/reviews/rpp2017-rev-resonances.pdf\n",
    "* Precision Electroweak Measurements on the Z Resonance (Combination LEP): https://arxiv.org/abs/hep-ex/0509008\n",
    "* Measurement of the $Z^0$ mass and width with the OPAL detector at LEP: https://doi.org/10.1016/0370-2693(89)90705-3\n",
    "* Measurement of the $Z^0$ line shape parameters and the electroweak couplings of charged leptons: https://inspirehep.net/literature/315269\n",
    "* The OPAL Collaboration, *Precise Determination of the $Z$ Resonance Parameters at LEP: \"Zedometry\"*: https://arxiv.org/abs/hep-ex/0012018\n",
    "* Fitting a Breit-Wigner curve using uproot: https://masonproffitt.github.io/uproot-tutorial/07-fitting/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 3: Forward-backward asymmetry and $\\sin^2(\\theta_\\text{W})$ in muon final states\n",
    "\n",
    "* Using the **muon channel only**, measure the forward-backward asymmetry $\\mathcal{A}_\\text{FB}$ using OPAL data and muon Monte Carlo events. Take into account the radiation corrections given below. \n",
    "\n",
    "| $\\sqrt{s}$   \\[GeV\\]| Radiation correction [-]|  \n",
    "| --- | --- | \n",
    "| 88.47 | 0.021512  | \n",
    "| 89.46 | 0.019262  | \n",
    "| 90.22 | 0.016713  | \n",
    "| 91.22 | 0.018293  | \n",
    "| 91.97 | 0.030286  | \n",
    "| 92.96 | 0.062196  | \n",
    "| 93.76 | 0.093850  | \n",
    "\n",
    "Feel free to use the dictionary 'radiation_corrections' given below.\n",
    "\n",
    "* Measure the **Weinberg angle** as $\\sin^2(\\theta_\\text{W})$. Compare the measurement with the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "radiation_corrections = { 'energy' : [ 88.47, 89.46, 90.22, 91.22, 91.97, 92.96, 93.76] ,\n",
    "                          'correction' : [0.021512, 0.019262, 0.016713, 0.018293, 0.030286, 0.062196, 0.093850]}\n",
    "mc_data = []\n",
    "data_data = [[],[]]\n",
    "mc_data_err = []\n",
    "data_data_err = [[],[]]\n",
    "\n",
    "for l,direction in enumerate([[['cos_thet', \">=\", -.7],['cos_thet', \"<\", 0]],\\\n",
    "                  [['cos_thet', \">\", 0],['cos_thet', \"<=\", .7]]]):\n",
    "    cut_mask_mc   = calculate_cuts(mm_cut_params + direction, files)\n",
    "    mc_events = sum(sum(c) for c in cut_mask_mc)\n",
    "    mc_data.append(mc_events)\n",
    "    mc_data_err.append(np.sqrt(mc_events))\n",
    "    for j in range(7):\n",
    "        cut_mask_data = calculate_cuts(mm_cut_params + direction + energy_cut_params[j], [data_file]) \n",
    "        data_events = sum(sum(c) for c in cut_mask_data)\n",
    "        data_data[l].append(data_events)\n",
    "        data_data_err[l].append(np.sqrt(data_events))\n",
    "    \n",
    "print(mc_data,data_data)\n",
    "print(mc_data_err,data_data_err)\n",
    "plt.plot(radiation_corrections['energy'],data_data[0])\n",
    "plt.plot(radiation_corrections['energy'],data_data[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 4: Tests on lepton universality¶\n",
    "\n",
    "* Test the lepton universality from the total cross sectinos on the peak for $Z\\to e^+ e^-$, $Z\\to \\mu^+ \\mu^-$ and $Z\\to \\tau^+ \\tau^-$ events. What is the ratio of the total cross section of the hadronic channel to the leptonic channels on the peak? Compare with the ratios obtained from the branching rations and discuss possible differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ROOT)",
   "language": "python",
   "name": "python3-root",
   "resource_dir": "/usr/local/share/jupyter/kernels/python3-root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}