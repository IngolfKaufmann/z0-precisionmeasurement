{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 1: Optimize lepton selection\n",
    "\n",
    "* First, print the distributions of the relevant variables for *all* the Monte Carlo samples (i.e. all the *channels* of the $Z$-boson decay to be studied). Which variables are these? Give sensible ranges to include all the events in the samples (both MC and OPAL data) \n",
    "* Do the same for **one** of the OPAL data samples (your lab assistant will decide which one you choose).\n",
    "* Describe the results.\n",
    "* Optimize the object selection by applying cuts. Make a strategy on how to proceed to find the optimal selection. which information do you need? in thin the\n",
    "* Determine the efficiency and the amount of background for each $Z$ decay channel. Use the simulated events $e^+e^-$, $\\mu^+\\mu^-$, $\\tau^+\\tau^-$ and hadrons ($qq$). Represent the result in a matrix form and think carefully about how you have to correct the measured rates. Don't forget to calculate the errors!\n",
    "* How do we estimate the statistical fluctuations per bin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Download missing libraries\n",
    "Comment in the following two lines in case some of the libraries cannot be imported. Please restart the kernel after download+upgrade has successfully finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "### Download libraries\n",
    "#%pip install uproot \n",
    "#%pip install awkward \n",
    "#%pip install mplhep \n",
    "#%pip install numpy \n",
    "#%pip install matplotlib \n",
    "#%pip install scipy\n",
    "\n",
    "### Upgrade libraries to latest version\n",
    "#%pip install uproot awkward mplhep numpy matplotlib scipy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import uproot #for the OPAL data and to use root\n",
    "import awkward as ak\n",
    "import mplhep\n",
    "%matplotlib inline\n",
    "import numpy as np #for calculations\n",
    "import matplotlib.pyplot as plt #to plot\n",
    "\n",
    "import csv #using \"csv\" to import the Luminosities\n",
    "from scipy.optimize import curve_fit #for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "colors = {'e' : 'b', 'm' : 'r', 't' : 'g', 'q' : 'y', 'mix' : 'black', 'es' : 'cornflowerblue', 'ecut' : 'lightblue', 'mcut' : 'Salmon', 'tcut' : 'limegreen', 'qcut' : 'gold'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "path_mc = 'opal_data/mc/' #Import path for MC data\n",
    "\n",
    "fileee = uproot.open(path_mc+'ee.root') # electron data\n",
    "filemm = uproot.open(path_mc+'mm.root') # muon data\n",
    "filett = uproot.open(path_mc+'tt.root') # tauon data\n",
    "fileqq = uproot.open(path_mc+'qq.root') # hadronic data\n",
    "\n",
    "files = [fileee, filemm, filett, fileqq] # list of data sets in uproot form\n",
    "\n",
    "ttree_name = 'myTTree'\n",
    "\n",
    "## Load branches to akward high level array\n",
    "branchesee = files[0][ttree_name].arrays() #Electronic brances of the MC data\n",
    "branchesmm = files[1][ttree_name].arrays() #Muonic brances ''\n",
    "branchestt = files[2][ttree_name].arrays() #Tauon branches ''\n",
    "branchesqq = files[3][ttree_name].arrays() #Quarks ''\n",
    "\n",
    "\n",
    "branchessum = 0 # Dummy variable for the sum of MC data\n",
    "branchesREAL = 0 # Dummy variable for the measured OPAL data\n",
    "\n",
    "# List of all MC data sets\n",
    "brancheses = [branchesee, branchesmm, branchestt, branchesqq, branchessum, branchesREAL] #List of all Branches\n",
    "\n",
    "## List of measured quantities\n",
    "var = ['Ncharged', 'Pcharged', 'E_ecal', 'E_hcal', 'E_lep', 'cos_thru', 'cos_thet', 'run', 'event']\n",
    "\n",
    "# Lists for the data of measured quantities\n",
    "pchares = [0] * 6 # 4 Times the MC data, 1 time the sum of MC and 1 Time the measured data\n",
    "nchares = [0] * 6\n",
    "eecal = [0] * 6\n",
    "ehcal = [0] * 6\n",
    "elep = [0] * 6\n",
    "costhru = [0] * 6\n",
    "costhet = [0] * 6\n",
    "\n",
    "run = [0] * 6\n",
    "event = [0] * 6\n",
    "i = 0\n",
    "# Loop over the four particle types\n",
    "while i < 4:\n",
    "    nchares[i] = ak.to_numpy(brancheses[i][var[0]]) #copy from strange array to nomal array.\n",
    "    pchares[i] = ak.to_numpy(brancheses[i][var[1]])\n",
    "    eecal[i] = ak.to_numpy(brancheses[i][var[2]])\n",
    "    ehcal[i] = ak.to_numpy(brancheses[i][var[3]])\n",
    "    elep[i] = ak.to_numpy(brancheses[i][var[4]])\n",
    "    costhru[i] = ak.to_numpy(brancheses[i][var[5]])\n",
    "    costhet[i] = ak.to_numpy(brancheses[i][var[6]])\n",
    "    run[i] = ak.to_numpy(brancheses[i][var[7]])\n",
    "    event[i] = ak.to_numpy(brancheses[i][var[8]])\n",
    "    i += 1\n",
    "\n",
    "# Add the cummulative data of all particle events to one list. \n",
    "#This is done to simulate a whole data set as given from the Detector later on.\n",
    "nchares[4] = np.concatenate((nchares[:4]),axis=None) # Sum the MC data to a total array\n",
    "pchares[4] = np.concatenate((pchares[:4]),axis=None)\n",
    "eecal[4] = np.concatenate((eecal[:4]),axis=None)\n",
    "ehcal[4] = np.concatenate((ehcal[:4]),axis=None)\n",
    "elep[4] = np.concatenate((elep[:4]),axis=None)\n",
    "costhru[4] = np.concatenate((costhru[:4]),axis=None)\n",
    "costhet[4] = np.concatenate((costhet[:4]),axis=None)\n",
    "run[4] = np.concatenate((run[:4]),axis=None)\n",
    "event[4] = np.concatenate((event[:4]),axis=None)\n",
    "\n",
    "# Re create a \"high level array\", for the MC cummulative data.\n",
    "brancheses[4] = ak.Array([\n",
    "    {\"run\": run[4], \"event\": event[4], 'Ncharged' : nchares[4], 'Pcharged' : pchares[4], 'E_ecal' : eecal[4], 'E_hcal' : ehcal[4], 'E_lep' : elep[4], 'cos_thru' : costhru[4], 'cos_thet' : costhet[4]} \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The last line shows all the variables available in the TTree to carry out the experiment. The meaning of these is described in the following table\n",
    "\n",
    "| Variable name | Description |\n",
    "| --- | --- | \n",
    "| <pre>run</pre> | Run number |\n",
    "| <pre>event</pre> | Event number |\n",
    "| <pre>Ncharged</pre> | Number of charged tracks |\n",
    "| <pre>Pcharged</pre> | Total scalar sum of track momenta |\n",
    "| <pre>E_ecal</pre> | Total energy measured in the electromagnetic calorimeter |\n",
    "| <pre>E_hcal</pre> | Total energy measured in the hadronic calorimete |\n",
    "| <pre>E_lep</pre> | LEP beam energy (=$\\sqrt{s}/2$) |\n",
    "| <pre>cos_thru</pre> | cosine of the polar angle between beam axis and thrust axis |\n",
    "| <pre>cos_thet</pre> | cosine of the polar angle between incoming positron and outgoing positive particle |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cut selection in the MC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Histogram the MC data of the charged traces\n",
    "plt.style.use(mplhep.style.ATLAS) # You can load ATLAS/CMS/ALICE plot style \n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "\n",
    "\n",
    "bin_content, bin_edges, ax1 = plt.hist(nchares[0], bins=100, range=(0.,100.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='electron ee', zorder=2)\n",
    "bin_content, bin_edges, _ = plt.hist(nchares[1], bins=100, range=(0.,100.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='muon mm', zorder=3)\n",
    "bin_content, bin_edges, _ = plt.hist(nchares[2], bins=100, range=(0.,100.), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='tauon tt', zorder=5)\n",
    "bin_content, bin_edges, _ = plt.hist(nchares[3], bins=100, range=(0.,100.), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='hadronic qq', zorder=4)\n",
    "#bin_content, bin_edges, _ = plt.hist(nchares[4], bins=100, range=(0.,100.), histtype='step',  linewidth=2, edgecolor=colors['mix'], hatch='/', label='sum', zorder=1)\n",
    "\n",
    "#vicualize the seperation cuts\n",
    "ax = plt.axvline(x=8, color = colors['qcut'], ls = '--', label = 'qq seperation')\n",
    "plt.axvline(x=6, color = colors['mcut'], ls = '--', label = 'mm seperation')\n",
    "plt.axvline(x=2.5, color = colors['tcut'], ls = '-', label = 'tt seperation')\n",
    "plt.axvline(x=2.5, color = colors['ecut'], ls = '--', label = 'ee seperation')\n",
    "\n",
    "\n",
    "### Show the plot on screen\n",
    "plt.legend()\n",
    "plt.title('MC data: charged tracks')\n",
    "plt.xlim(-1,35)\n",
    "plt.ylim(0,40e3)\n",
    "plt.xlabel('Ncharged')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Plot of the total particle \n",
    "plt.style.use(mplhep.style.ATLAS) \n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(pchares[0], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='ee')\n",
    "bin_content, bin_edges, _ = plt.hist(pchares[1], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='mm')\n",
    "bin_content, bin_edges, _ = plt.hist(pchares[2], bins=1000, range=(0.,200), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='tt')\n",
    "bin_content, bin_edges, _ = plt.hist(pchares[3], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='qq')\n",
    "bin_content, bin_edges, _ = plt.hist(pchares[4], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['mix'], hatch='/', label='sum', zorder=1)\n",
    "\n",
    "#vicualize the seperation cuts\n",
    "plt.axvline(x=75, color = colors['mcut'], ls = '--', label = 'mm seperation')\n",
    "plt.axvline(x=73, color = colors['tcut'], ls = '--', label = 'tt seperation')\n",
    "### Show the plot on screen\n",
    "plt.legend()\n",
    "plt.title('MC data: Total track momenta')\n",
    "#plt.xlim(-5,130.)\n",
    "plt.xlim(-5,125)\n",
    "plt.ylim(0,3e3)\n",
    "plt.xlabel('$p_{track}$')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS) # You can load ATLAS/CMS/ALICE plot style \n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(eecal[0], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='ee')\n",
    "bin_content, bin_edges, _ = plt.hist(eecal[1], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='mm')\n",
    "bin_content, bin_edges, _ = plt.hist(eecal[2], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='tt')\n",
    "bin_content, bin_edges, _ = plt.hist(eecal[3], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='qq')\n",
    "bin_content, bin_edges, _ = plt.hist(eecal[4], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['mix'], hatch='/', label='sum', zorder=1)\n",
    "\n",
    "plt.axvline(x=50, color = colors['ecut'], ls = '-', label = 'ee seperation')\n",
    "#vicualize the seperation cuts\n",
    "plt.axvline(x=50, color = colors['mcut'], ls = '--', label = 'mm seperation')\n",
    "plt.axvline(x=70, color = colors['tcut'], ls = '--', label = 'tt seperation')\n",
    "### Show the plot on screen\n",
    "plt.legend()\n",
    "plt.title('MC data: Energy in electronic calorimeter')\n",
    "plt.xlim(-5.,170)\n",
    "plt.ylim(0,3e3)\n",
    "plt.xlabel('$E_{ecal}$')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS) # You can load ATLAS/CMS/ALICE plot style \n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(ehcal[0], bins=200, range=(0.,40.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='ee')\n",
    "bin_content, bin_edges, _ = plt.hist(ehcal[1], bins=200, range=(0.,40.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='mm')\n",
    "bin_content, bin_edges, _ = plt.hist(ehcal[2], bins=200, range=(0.,40.), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='tt')\n",
    "bin_content, bin_edges, _ = plt.hist(ehcal[3], bins=200, range=(0.,40.), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='qq')\n",
    "bin_content, bin_edges, _ = plt.hist(ehcal[4], bins=200, range=(0.,40.), histtype='step',  linewidth=2, edgecolor=colors['mix'], hatch='/', label='sum', zorder=1)\n",
    "\n",
    "### Show the plot on screen\n",
    "plt.legend()\n",
    "plt.title('MC data: energy in hadronic calorimeter')\n",
    "plt.xlim(-1,40)\n",
    "plt.ylim(0,8000)\n",
    "plt.xlabel('$E_{hcal}$')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS) # You can load ATLAS/CMS/ALICE plot style \n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "#bin_content, bin_edges, _ = plt.hist(pchar[mymask], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor='b', hatch='/', label='Pcharged')\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(elep[0], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='e')\n",
    "bin_content, bin_edges, _ = plt.hist(elep[1], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='m')\n",
    "bin_content, bin_edges, _ = plt.hist(elep[2], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='t')\n",
    "bin_content, bin_edges, _ = plt.hist(elep[3], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='q')\n",
    "\n",
    "\n",
    "mid = 0.5*(bin_edges[1:] + bin_edges[:-1]) #Calculate midpoint of the bars\n",
    "\n",
    "error_sizes = np.sqrt(bin_content)\n",
    "\n",
    "#plt.errorbar(mid, bin_content, yerr=error_sizes, fmt='none', label='Errors')\n",
    "### When producing an histogram, you can store the bin content and the edges of the bins in \n",
    "###'bin_content', and 'bin_edges' \n",
    "#print(bin_content)\n",
    "#print(bin_edges)\n",
    "\n",
    "### Show the plot on screen\n",
    "plt.legend()\n",
    "plt.title('Lep energy')\n",
    "plt.xlim(44,48.)\n",
    "plt.ylim(0,1e5)\n",
    "plt.xlabel('Energy of the Lep beam')\n",
    "plt.ylabel('Number of events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS) # You can load ATLAS/CMS/ALICE plot style \n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(costhru[0], bins=200, range=(-1,1.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='e')\n",
    "bin_content, bin_edges, _ = plt.hist(costhru[1], bins=200, range=(-1,1.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='m')\n",
    "bin_content, bin_edges, _ = plt.hist(costhru[2], bins=200, range=(-1,1.), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='t')\n",
    "bin_content, bin_edges, _ = plt.hist(costhru[3], bins=200, range=(-1,1.), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='q')\n",
    "#bin_content, bin_edges, _ = plt.hist(costhet[4], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor='black', hatch='/', label='sum', zorder=1)\n",
    "\n",
    "\n",
    "### Show the plot on screen\n",
    "plt.legend()\n",
    "plt.title(var[5])\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(0,1000)\n",
    "plt.xlabel('Total scalar sum of track momenta, $p_{track}$')\n",
    "plt.ylabel('Number of events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS) # You can load ATLAS/CMS/ALICE plot style \n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "x_min =-1\n",
    "x_max = 1\n",
    "bin_content, bin_edges, _ = plt.hist(costhet[0], bins=200, range=(x_min,x_max), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='ee')\n",
    "bin_content, bin_edges, _ = plt.hist(costhet[1], bins=200, range=(x_min,x_max), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='mm')\n",
    "bin_content, bin_edges, _ = plt.hist(costhet[2], bins=200, range=(x_min,x_max), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='tt')\n",
    "bin_content, bin_edges, _ = plt.hist(costhet[3], bins=200, range=(x_min,x_max), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='qq')\n",
    "#bin_content, bin_edges, _ = plt.hist(costhet[4], bins=1000, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['mix'], hatch='/', label='sum', zorder=1)\n",
    "\n",
    "\n",
    "\n",
    "### Show the plot on screen\n",
    "plt.legend(loc = 9)\n",
    "plt.title('MC data: Scattering angle')\n",
    "plt.xlim(x_min-0.05,x_max+0.05)\n",
    "plt.ylim(0,1000)\n",
    "plt.xlabel(r'Scattering angle $cos(\\theta)$')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cut application in MC data and efficiency matrix\n",
    "Cuts, selected in the Monte Carlo data, to separate the particle classes from each other.\n",
    "\n",
    "The cutting condition is applied in the \"high level array\". The resulting masks consit of \"True\" or \"False\" entries. Adding up all the created masks for one particle class results in the total cutting mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Cuts, to separate the electrons and find the wrong particles in the electron cut\n",
    "ecuts = [0] * 6\n",
    "i = 0\n",
    "while i < 4: #Index 0 to find the electron and all other indices to find the wrong fermions in the electron cut\n",
    "    emasks = [0] * 6\n",
    "    emasks[0] = brancheses[i]['E_ecal'] >= 50 #to separate electrons from muons\n",
    "    emasks[1] = brancheses[i]['E_ecal'] >= 68 #redundant cut to separate electrons from tauons\n",
    "    emasks[2] = brancheses[i]['Ncharged'] <= 2  #to separate electrons from Hadrons and eliminate more photon events\n",
    "    ecuts[i] = emasks[0] & emasks[1] & emasks[2] #combining the masks\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "# Cuts, to separate the muons and find the wrong particles in the muon cut\n",
    "mcuts = [0] * 6\n",
    "i = 0\n",
    "while i < 4: #Index 1 to find the muons and all other indices to find the wrong fermions in the muon cut\n",
    "    mmasks = [0] * 4\n",
    "    mmasks[0] = brancheses[i]['E_ecal'] <= 50 #to separate the muons from electrons\n",
    "    mmasks[1] = brancheses[i]['Pcharged'] >= 75 #to separate the muons from tauons\n",
    "    mmasks[2] = brancheses[i]['Ncharged'] ==2 #to separate the muons from hadrons\n",
    "    mcuts[i] = mmasks[0] & mmasks[1] & mmasks[2]\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "tcuts = [0] * 6\n",
    "i = 0\n",
    "while i < 4: #Index 2 to find the tauons and all other indices to find the wrong fermions in the tauon cut\n",
    "    tmasks = [0] * 4\n",
    "    tmasks[0] = brancheses[i]['E_ecal'] <= 70 #to separate tauons from electrons\n",
    "    tmasks[1] = brancheses[i]['Pcharged'] <= 73 #to separate tauons from muons\n",
    "    tmasks[3] = brancheses[i]['Pcharged'] >= 3  #to recalculate the 0 track events\n",
    "    tmasks[2] = brancheses[i]['Ncharged'] <= 7 #to separate the hadrons\n",
    "    tcuts[i] =  tmasks[1] & tmasks[2] & tmasks[0] & tmasks[3]\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "qcuts = [0] * 6\n",
    "i = 0\n",
    "while i < 4:\n",
    "    qmasks = [0] * 3\n",
    "    qmasks[0] = brancheses[i]['Ncharged'] >= 8 #to separate the hadrons\n",
    "    qmasks[1] = brancheses[i]['Ncharged'] >= 8\n",
    "    qmasks[2] = brancheses[i]['Ncharged'] >= 8\n",
    "    qcuts[i] = qmasks[0] & qmasks[1] & qmasks[2]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# Creation of the recalculation matrix A\n",
    "N = 100000 # Total number of simulated events per fermion class\n",
    "Ne = N # Number of simulated electron events\n",
    "Nm = N # Number of simulated muon events\n",
    "Nt = N # Number of simulated tauon events\n",
    "Nq = N # Number of simulated hadron events\n",
    "\n",
    "# Number of events in the events of a fermion class (column) in a fermion chanel (line)\n",
    "k = np.array([[np.sum(ecuts[0]), np.sum(ecuts[1]), np.sum(ecuts[2]), np.sum(ecuts[3])],\n",
    "              [np.sum(mcuts[0]), np.sum(mcuts[1]), np.sum(mcuts[2]), np.sum(mcuts[3])],\n",
    "              [np.sum(tcuts[0]), np.sum(tcuts[1]), np.sum(tcuts[2]), np.sum(tcuts[3])],\n",
    "              [np.sum(qcuts[0]), np.sum(qcuts[1]), np.sum(qcuts[2]), np.sum(qcuts[3])]\n",
    "             ])\n",
    "\n",
    "# Total Number events simulated per fermion class\n",
    "n = np.array([[Ne,Nm,Nt,Nq],\n",
    "              [Ne,Nm,Nt,Nq],\n",
    "              [Ne,Nm,Nt,Nq],\n",
    "              [Ne,Nm,Nt,Nq]\n",
    "              ])\n",
    "\n",
    "# Clalculation the Efficiency Matrix by deviding obverved events by expected events (deviding element not as matrices)\n",
    "A = k / n\n",
    "\n",
    "# Applying Bayesian Statistics to determine the Variance (and error with sqrt) of the Efficiency Matrix\n",
    "A_err = np.sqrt(((k+1)*(k+2)/((n+2)*(n+3))) - ((k+1)**2/(n+2)**2))\n",
    "\n",
    "\n",
    "print('Efficiency Matrix A:')\n",
    "print(np.array_repr(A, precision=7, suppress_small=True),'\\n')\n",
    "\n",
    "print('Errors of efficiency Matrix A_err:')\n",
    "print(np.array_repr(A_err, precision=7, suppress_small=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "A_inv = np.linalg.inv(A)# Matrix inversion of the efficiency Matrix\n",
    "print('Correction Matrix A_inv, the inverse of the efficiency Matrix')\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Analytical error determination to the inverse Matrix.\n",
    "\n",
    "The calculation follows the description in:  https://arxiv.org/abs/hep-ex/9909031v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "A_inv_err = np.zeros((4,4)) #Creating the inverse Matrix\n",
    "\n",
    "#Loops over entries in the inverse matrix and entries of the error matrix.\n",
    "i = 0\n",
    "while i < 4:\n",
    "    j = 0\n",
    "    while j < 4:\n",
    "        m = 0\n",
    "        while m < 4:\n",
    "            n = 0\n",
    "            while n < 4:\n",
    "                A_inv_err[i,j] += (A_inv[i,m] * A_err[m,n] * A_inv[n,j])**2\n",
    "                n += 1\n",
    "            m += 4\n",
    "        A_inv_err[i,j] =  np.sqrt((A_inv_err[i,j]))\n",
    "        j += 1\n",
    "    i += 1\n",
    "print('Errors of the inverse matrix:')\n",
    "print(A_inv_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cutting in the sum of the MC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To test the selected cuts, they are applied on the sum of all Monte Carlo data. The summ of all MC data is stored in \"brancheses[4]\" and the same cuts as above are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "i = 4 #Index of the sum of the MC data\n",
    "\n",
    "#Applying the same cuts as above\n",
    "emasks = [0] * 3 \n",
    "emasks[0] = brancheses[i]['E_ecal'] >= 50\n",
    "emasks[1] = brancheses[i]['E_ecal'] >= 68\n",
    "emasks[2] = brancheses[i]['Ncharged'] <= 2\n",
    "ecuts[i] = emasks[0] & emasks[1] & emasks[2] #Total mask after electron cutting\n",
    "\n",
    "\n",
    "mmasks = [0] * 4\n",
    "mmasks[0] = brancheses[i]['E_ecal'] <= 50\n",
    "mmasks[1] = brancheses[i]['Pcharged'] >= 75\n",
    "mmasks[2] = brancheses[i]['Ncharged'] == 2\n",
    "mcuts[i] = mmasks[0] & mmasks[1] & mmasks[2] #Total mask after muon cutting\n",
    "\n",
    "\n",
    "tmasks = [0] * 4\n",
    "tmasks[0] = brancheses[i]['E_ecal'] <= 70\n",
    "tmasks[1] = brancheses[i]['Pcharged'] <= 73\n",
    "tmasks[3] = brancheses[i]['Pcharged'] >= 3\n",
    "tmasks[2] = brancheses[i]['Ncharged'] <= 7\n",
    "tcuts[i] =  tmasks[1] & tmasks[2] & tmasks[0] & tmasks[3] #Total mask after tauon cutting\n",
    "\n",
    "\n",
    "qmasks = [0] * 3\n",
    "qmasks[0] = brancheses[i]['Ncharged'] >= 8\n",
    "qmasks[1] = brancheses[i]['Ncharged'] >= 8\n",
    "qmasks[2] = brancheses[i]['Ncharged'] >= 8\n",
    "qcuts[i] = qmasks[0] & qmasks[1] & qmasks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Test wether the recalculation to the total particle numbers after cutting works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "e_tot_cut = np.sum(ecuts[4]) #Number of electrons after cutting (mixed with other particles)\n",
    "m_tot_cut = np.sum(mcuts[4])\n",
    "t_tot_cut = np.sum(tcuts[4])\n",
    "q_tot_cut = np.sum(qcuts[4])\n",
    "\n",
    "# Dot product of the recalculation Matrix A_inv with the vector of cuttet particles.\n",
    "B = A_inv.dot(np.array([e_tot_cut, m_tot_cut, t_tot_cut, q_tot_cut]) )\n",
    "\n",
    "print('Recalculated particle numbers:')\n",
    "print('Total number of electrons: {0:6.0f}, muons: {1:6.0f}, tauons {3:6.0f} and hadrons: {4:6.0f}' .format(B[0],B[1],B[1],B[2],B[3]))\n",
    "print('Check, total number is matching!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 2: Separate $t$- and $s$-channel contributions\n",
    "\n",
    "Only Feynman diagrams contributing to the production of $Z$ boson are to be considered for the measurements. The **electron** Monte Carlo sample incorporate contributions from $t$- and $s$-channels.\n",
    "* Select/correct contributions producing $Z$ boson decays. (Hint: Which role does the $\\cos(\\theta)$ distribution play in separating $t$- and $s$-channels?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As an example this seperation is done in the MC total data, to demonstrate how it is done later on with the measured data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "Nbins = 200\n",
    "# Cutting the electrons out of the total MC data\n",
    "electrons_cut =costhet[4][ecuts[4]] \n",
    "# The electrons are not corrected, cause this correction is only done for the summ of all scatterd electrons. Not bin wise for the scattered electrons depending on the angle.\n",
    "# Histogramming the cos(theta) data\n",
    "e_cut, bin_edges, = np.histogram(electrons_cut, bins=Nbins, range=(-1,1))\n",
    "mid = 0.5*(bin_edges[1:] + bin_edges[:-1]) # Finding the mid between the bins on the x axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Define fit function. \n",
    "# The fit funciton consists of two parts. One for the s-channel and one for the t-channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dsigdtheta(theta,A,B):\n",
    "    '''Total fit function to separate s- and t-channel. \n",
    "    First part with the scaling parameter A for the s-channel and the second part with the scaling parameter B for the t-channel.\n",
    "    \n",
    "    Args:\n",
    "        A (float): Scaling for the s-channel\n",
    "        B (float): Scaling for the t-channel\n",
    "    '''\n",
    "    y = A*(1+theta**2)+B*(1-theta)**(-2)\n",
    "    return y\n",
    "def sdsig(theta,A):\n",
    "    '''Representation of the s-channel. With the scaling parameter A\n",
    "    \n",
    "    Args:\n",
    "        A (float): Scaling for the s-channel\n",
    "    '''\n",
    "    return A*(1+theta**2)\n",
    "def tdsig(theta,B):\n",
    "    '''Representation of the t-channel. With the scaling parameter B\n",
    "    \n",
    "    Args:\n",
    "        B (float): Scaling for the t-channel\n",
    "    '''\n",
    "    return B*(1-theta)**(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS) # You can load ATLAS/CMS/ALICE plot style \n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "# Subtracting t channel\n",
    "bin_min = 10\n",
    "bin_max = int(950/5)\n",
    "x_min = mid[bin_min]\n",
    "x_max = mid[bin_max]\n",
    "x_min_e_cut = x_min\n",
    "x_max_e_cut = x_max\n",
    "\n",
    "coeff, var_matrix  =curve_fit(dsigdtheta,mid[bin_min:bin_max],e_cut[bin_min:bin_max])\n",
    "hist_fit = dsigdtheta(mid[bin_min:bin_max],*coeff)\n",
    "fit_s_chan = sdsig(mid,coeff[0])\n",
    "\n",
    "#Analytical integral of the s channal betweenn -1 and 1 devided by the total number of electrons\n",
    "s_partial = coeff[0] * (8 / 3) * len(fit_s_chan) / (sum(e_cut)*2) \n",
    "\n",
    "#Gaussian error clalculation\n",
    "N_err = np.sqrt(sum(e_cut))\n",
    "s_partial_err =np.sqrt(((8 / 3) * (len(fit_s_chan) / (sum(e_cut)*2))**2) * var_matrix[0][0] + (coeff[0] * (8 / 3) * len(fit_s_chan) / (sum(e_cut)*2)**2 )**2 * N_err**2)   \n",
    "print('Ratio of the s part between -1 and 1 of the total counts:{:1.3f} +- {:1.3f}'.format(s_partial, s_partial_err) )\n",
    "\n",
    "e_cut_err = np.sqrt(e_cut)\n",
    "plt.title('MC: electron t - s seperation')\n",
    "plt.errorbar(mid, e_cut, yerr=e_cut_err, label = 'electrons', fmt=\".\", color=colors['mix'], zorder=1)\n",
    "#plt.plot(mid, e_cut, label = 'electrons', color=colors['e'])\n",
    "plt.axvline(x=0.9, color = 'k', ls = '--', label = 'fit boundary')\n",
    "plt.axvline(x=-0.9, color = 'k', ls = '--', label = 'fit boundary')\n",
    "\n",
    "plt.plot(mid[bin_min:bin_max],hist_fit,label = 't+s fit',color = colors['e'] )\n",
    "plt.plot(mid,fit_s_chan, label = 's part', color = colors['es'])\n",
    "plt.xlabel(r'$cos{\\theta}$')\n",
    "plt.ylabel('N')\n",
    "plt.grid()\n",
    "plt.ylim(0,1000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As it is done here for the MC data, the t and s seperation is done in the measurement for each energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 3: Measurement of the total production cross sections\n",
    "\n",
    "For **each** of the seven centre-of-mass energies:\n",
    "* Determine the number of events in the handronic channel *and* in the three leptonic channels\n",
    "* Substract the background and correct for selection efficiencies accordingly\n",
    "* Then, calculate the differnetial cross sections for the hadronic *and* the leptnic channels\n",
    "* Add the radiation corrections from The table given below. **Don't forget to take the uncertainties (errors) into account!**\n",
    "\n",
    "| $\\sqrt{s}$   \\[GeV\\]| Correction hadronic channel    \\[nb\\] |  Correction leptonic channel   \\[nb\\]|\n",
    "| --- | --- | --- |\n",
    "| 88.47 | +2.0  | +0.09 |\n",
    "| 89.46 | +4.3  | +0.20 |\n",
    "| 90.22 | +7.7  | +0.36 |\n",
    "| 91.22 | +10.8 | +0.52 |\n",
    "| 91.97 | +4.7  | +0.22 |\n",
    "| 92.96 | -0.2  | -0.01 |\n",
    "| 93.76 | -1.6  | -0.08 |\n",
    "\n",
    "Feel free to access these values using the dictionary 'xs_corrections' given below.\n",
    "* Once the total cross section for all four decay channels at all seven energies have been measured, fit a **Breit-Wigner distribution** to measure the $Z$ boson mass ($m_Z$) and the resonance width ($\\Gamma_Z$) and the peak cross section s of the resonance for the hadronic and the leptonic channels. Again, **propagate the uncertainties carefully**.\n",
    "* Compare your results to the OPAL cross section s and the theoretical predictions. How many degrees of freedom does the fit have? How can you udge if the model is compatible with the measured data? Calculate the  **confidence levels**.\n",
    "* Calculate the partial widths for all channels from the measured cross sections on the peak. Which is the best partial width to start with? Compare them with the theoretical predictions and the values that you have calculated in the beginning.\n",
    "* Determine from your results the **number of generations of light neutrinos**. Which assumptions are necessary?\n",
    "* Discuss in detail the systematic uncertainties in the whole procedure of the analysis. Which assumptions were necessary?\n",
    "\n",
    "These are some **references** that might be interesting to look up:\n",
    "* Particle Data Book: https://pdg.lbl.gov/2020/download/Prog.Theor.Exp.Phys.2020.083C01.pdf\n",
    "** Resonances: https://pdg.lbl.gov/2017/reviews/rpp2017-rev-resonances.pdf\n",
    "* Precision Electroweak Measurements on the Z Resonance (Combination LEP): https://arxiv.org/abs/hep-ex/0509008\n",
    "* Measurement of the $Z^0$ mass and width with the OPAL detector at LEP: https://doi.org/10.1016/0370-2693(89)90705-3\n",
    "* Measurement of the $Z^0$ line shape parameters and the electroweak couplings of charged leptons: https://inspirehep.net/literature/315269\n",
    "* The OPAL Collaboration, *Precise Determination of the $Z$ Resonance Parameters at LEP: \"Zedometry\"*: https://arxiv.org/abs/hep-ex/0012018\n",
    "* Fitting a Breit-Wigner curve using uproot: https://masonproffitt.github.io/uproot-tutorial/07-fitting/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "xs_corrections = { 'energy' : [ 88.47, 89.46, 90.22, 91.22, 91.97, 92.96, 93.76] ,\n",
    "                   'hadronic' : [2.0, 4.3, 7.7, 10.8, 4.7, -0.2, -1.6],\n",
    "                   'leptonic' : [0.09, 0.20, 0.36, 0.52, 0.22, -0.01, -0.08]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Import Opal data\n",
    "data_nr = 1 #selected data set \n",
    "\n",
    "path_opal = 'opal_data/data/daten_' +str(data_nr) +'.root' #File path\n",
    "data = uproot.open(path_opal) #import data\n",
    "\n",
    "\n",
    "branchesopal = data[ttree_name].arrays() #write \"high level\" array\n",
    "\n",
    "ncharesopal = ak.to_numpy(branchesopal[var[0]]) #copy from strange array to nomal array.\n",
    "pcharesopal = ak.to_numpy(branchesopal[var[1]])\n",
    "eecalopal = ak.to_numpy(branchesopal[var[2]])\n",
    "ehcalopal = ak.to_numpy(branchesopal[var[3]])\n",
    "elepopal = ak.to_numpy(branchesopal[var[4]])\n",
    "costhruopal = ak.to_numpy(branchesopal[var[5]])\n",
    "costhetopal = ak.to_numpy(branchesopal[var[6]])\n",
    "runopal = ak.to_numpy(branchesopal[var[7]])\n",
    "eventopal = ak.to_numpy(branchesopal[var[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Plot all OPAL data over the beam energy\n",
    "plt.style.use(mplhep.style.ATLAS)\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(elepopal, bins=1000, range=(44.,47.), histtype='step',  linewidth=2, edgecolor=colors['mix'], hatch='/', label='all events mixed', color=colors['mix'])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Lep energy')\n",
    "plt.xlim(44.,47)\n",
    "plt.xlabel('Energy of the Lep beam')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Applying the previously determined cuts on the Opal data, to separate the particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "opalEcuts = [0] * 7 #Dummy for cutted electrons\n",
    "opalMcuts = [0] * 7 #Dummy for cutted muons\n",
    "opalTcuts = [0] * 7 #Dummy for cutted tauons\n",
    "opalQcuts = [0] * 7 #Dummy for cutted hadrons\n",
    "\n",
    "#Creation of an additional cut, to separate the energies.\n",
    "# The cut boundaries are read out from the plot above.\n",
    "EnergyCutsUP = [44.4, 44.9, 45.2, 45.8, 46.1, 46.6, 47.0]\n",
    "EnergyCutsLP = [44.0, 44.6, 45.0, 45.4, 45.9, 46.4, 46.8]\n",
    "\n",
    "# Cutting the Opal data as done for the MC data, with an additional energy cut\n",
    "#Electrons\n",
    "i = 0\n",
    "while i < 7: #Loop over all beam energies\n",
    "    emasks = [0] * 5\n",
    "    emasks[0] = branchesopal['E_ecal'] >= 50\n",
    "    emasks[1] = branchesopal['E_ecal'] >= 68\n",
    "    emasks[2] = branchesopal['Ncharged'] <=2\n",
    "    #Energy cut\n",
    "    emasks[3] = branchesopal['E_lep'] >= EnergyCutsLP[i]\n",
    "    emasks[4] = branchesopal['E_lep'] <= EnergyCutsUP[i]\n",
    "    opalEcuts[i] = emasks[0] & emasks[1] & emasks[2] & emasks[3] & emasks[4]\n",
    "    i += 1\n",
    "\n",
    "#Muons\n",
    "i = 0\n",
    "while i < 7:\n",
    "    mmasks = [0] * 5\n",
    "    mmasks[0] = branchesopal['E_ecal'] <= 20\n",
    "    mmasks[1] = branchesopal['Pcharged'] >= 75\n",
    "    mmasks[2] = branchesopal['Ncharged'] <=2\n",
    "    #Energy\n",
    "    mmasks[3] = branchesopal['E_lep'] >= EnergyCutsLP[i]\n",
    "    mmasks[4] = branchesopal['E_lep'] <= EnergyCutsUP[i]\n",
    "    \n",
    "    opalMcuts[i] = mmasks[0] & mmasks[1] & mmasks[2] & mmasks[3] & mmasks[4] \n",
    "    i += 1\n",
    "\n",
    "#Tauons\n",
    "i = 0\n",
    "while i < 7:\n",
    "    tmasks = [0] * 6\n",
    "    tmasks[0] = branchesopal['E_ecal'] <= 70\n",
    "    tmasks[1] = branchesopal['Pcharged'] <= 73\n",
    "    tmasks[5] = branchesopal['Pcharged'] >= 3 #tauon optimierung\n",
    "    tmasks[2] = branchesopal['Ncharged'] <= 7\n",
    "    #Energy\n",
    "    tmasks[3] = branchesopal['E_lep'] >= EnergyCutsLP[i]\n",
    "    tmasks[4] = branchesopal['E_lep'] <= EnergyCutsUP[i]\n",
    "\n",
    "    opalTcuts[i] =  tmasks[1] & tmasks[2] & tmasks[0] & tmasks[3] & tmasks[4] & tmasks[5]\n",
    "    i += 1\n",
    "\n",
    "# Hadrons\n",
    "i = 0\n",
    "while i < 7:\n",
    "    qmasks = [0] * 5\n",
    "    qmasks[0] = branchesopal['Ncharged'] >= 8\n",
    "    qmasks[1] = branchesopal['Ncharged'] >= 8\n",
    "    qmasks[2] = branchesopal['Ncharged'] >= 8\n",
    "    #Energy\n",
    "    qmasks[3] = branchesopal['E_lep'] >= EnergyCutsLP[i]\n",
    "    qmasks[4] = branchesopal['E_lep'] <= EnergyCutsUP[i]\n",
    "    opalQcuts[i] = qmasks[0] & qmasks[1] & qmasks[2] & qmasks[3] & qmasks[4]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Rescaling the measured chenals acorddin to the efficiency matrix\n",
    "opalB = [0] * 7\n",
    "f = [0] * 7\n",
    "f_err = [0] * 7\n",
    "\n",
    "i = 0\n",
    "while i < 7:\n",
    "    f[i] = np.array([np.sum(opalEcuts[i]), np.sum(opalMcuts[i]), np.sum(opalTcuts[i]), np.sum(opalQcuts[i])])# Vector of measured data in each chenal\n",
    "    f_err[i] = np.array([np.sqrt(f[i][0]), np.sqrt(f[i][1]), np.sqrt(f[i][2]), np.sqrt(f[i][3])])# Error on the measurement vector\n",
    "    opalB[i] = A_inv.dot(f[i])# Using the above opained efficiency matrix to rescale the measured chenals\n",
    "    i += 1\n",
    "\n",
    "opalB_err = [0] * 7\n",
    "\n",
    "# Calculating the errors for the rescaled chenals\n",
    "k = 0\n",
    "while k < 7:# loop over all lep energies\n",
    "    opalB_err[k] = [0] * 4\n",
    "    i = 0\n",
    "    while i < 4:# loop over all chenals (types of fermions)\n",
    "        j = 0\n",
    "        while j < 4:# loop over other (not exluding i) chenals\n",
    "            # to get the error for the index i a sum over j is pervormed\n",
    "            opalB_err[k][i] += (A_inv[i,j]**2 * f_err[k][j]**2 + A_inv_err[i,j]**2 * f[k][j]**2)\n",
    "            j += 1\n",
    "        opalB_err[k][i] = np.sqrt(opalB_err[k][i])\n",
    "        i += 1\n",
    "    k += 1\n",
    "\n",
    "# Printing all rescaled event counts\n",
    "tpye = ['ee', 'mm', 'tt', 'qq']\n",
    "for ii in range(7):\n",
    "    print('\\nEnergy of LEP E = {:4.2f}:'.format(xs_corrections['energy'][ii]))\n",
    "    for jj in range(4):\n",
    "        print('Number of {} events = {:4.0f} +- {:4.0f}'.format(tpye[jj], opalB[ii][jj], opalB_err[ii][jj]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Import Luminosities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "lumi_data = 'opal_data/lumi_files/daten_' +str(data_nr) +'.lum' #File path\n",
    "\n",
    "\n",
    "energy = np.zeros(7) #beam energies\n",
    "lumi = np.zeros(7) #luminosity\n",
    "err_all_lumi = np.zeros(7)\n",
    "\n",
    "with open(lumi_data, newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for jj,row in enumerate(spamreader):\n",
    "        if jj >0:\n",
    "            energy[jj-1] = float(row[0])\n",
    "            lumi[jj-1] = float(row[1])\n",
    "            err_all_lumi[jj-1] = float(row[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* t and s seperation for electron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "opal_e_cut_E = []\n",
    "opal_e_cut_mid = []\n",
    "Nbins_opal = 30\n",
    "for i in range(7):\n",
    "    E, bin_edge, = np.histogram(costhetopal[opalEcuts[i]], bins=Nbins_opal, range=(-1,1))\n",
    "    mid = 0.5*(bin_edge[1:] + bin_edge[:-1])\n",
    "\n",
    "    opal_e_cut_E.append(E)\n",
    "    opal_e_cut_mid.append(mid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def chi2(data, fit, err_data,ndf):\n",
    "    '''Calculation of chisquare over ndf.\n",
    "    \n",
    "    Args: \n",
    "        data: Measured data points\n",
    "        fit: fit data points\n",
    "        err_data: Errors on the measured data points\n",
    "        ndf: Number of degree of freedom (number of data points - fit parameter)\n",
    "    '''\n",
    "    chisquare = sum((data-fit)**2/err_data**2)\n",
    "    return chisquare/ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Fitting\n",
    "# Subtracting t channel\n",
    "bin_min_opal = int(2)\n",
    "bin_max_opal = int(27)\n",
    "\n",
    "x_min = mid[bin_min_opal]\n",
    "x_max = mid[bin_max_opal]\n",
    "print('Range for fitting: cos(theta)=', x_min,'to', x_max)\n",
    "fit_s_chan = []\n",
    "fit_ts_chan = []\n",
    "fig, ax = plt.subplots(2, 4, figsize=(20, 10))\n",
    "ax[-1, -1].axis('off')\n",
    "\n",
    "energy = xs_corrections['energy']\n",
    "ratio_s_opal = []\n",
    "ratio_s_opal_err = []\n",
    "chi_ts = np.zeros(7)\n",
    "for ii in range(7):\n",
    "    error_sizes = np.sqrt(opal_e_cut_E[ii])\n",
    "    \n",
    "    coeff, var_matrix = curve_fit(dsigdtheta, opal_e_cut_mid[ii][bin_min_opal:bin_max_opal], opal_e_cut_E[ii][bin_min_opal:bin_max_opal])\n",
    "    hist_fit = dsigdtheta(mid[bin_min_opal:bin_max_opal], *coeff)\n",
    "    fit_s_chan.append( sdsig(mid, coeff[0]))\n",
    "    x = np.linspace(mid[2],mid[28],200)\n",
    "    fit_ts_chan.append( dsigdtheta(x,*coeff))\n",
    "    jj = ii\n",
    "    line = 0 #line number\n",
    "    if ii>3: #go into the second line\n",
    "        line = 1 #second line\n",
    "        ii = ii-4 #column number\n",
    "        \n",
    "    chi_ts[jj] = chi2(opal_e_cut_E[jj][bin_min_opal:bin_max_opal],dsigdtheta(opal_e_cut_mid[jj][bin_min_opal:bin_max_opal],*coeff),error_sizes[bin_min_opal:bin_max_opal], len(error_sizes[bin_min_opal:bin_max_opal])-2)\n",
    "    im = ax[line, ii].errorbar(opal_e_cut_mid[ii], opal_e_cut_E[ii], yerr=error_sizes, label = 'Energy: {}'.format(energy[jj]), fmt=\".\", color=colors['mix'], zorder=1)\n",
    "    im = ax[line, ii].plot(opal_e_cut_mid[ii],fit_s_chan[ii], zorder=3, label='s komponent of the Fit', color=colors['es'])\n",
    "    im = ax[line, ii].plot(x,fit_ts_chan[ii], zorder=2, label=\n",
    "                           'Fit of s+t chanel \\n $ \\chi ^2 / ndf $ ={:1.2}'.format(chi_ts[jj]), color=colors['e'])\n",
    "    im = ax[line, ii].legend()\n",
    "    \n",
    "    ratio_s_opal.append(coeff[0] * (8 / 3) * len(fit_s_chan[ii]) / (sum(opalEcuts[ii])*2) )\n",
    "    ratio_s_opal_err.append(np.sqrt(((8 / 3) * (len(fit_s_chan[ii]) / (sum(opalEcuts[ii])*2))**2) * var_matrix[0][0] + (coeff[0] * (8 / 3) * len(fit_s_chan[ii]) / (sum(opalEcuts[ii])*2)**2 )**2 * opalB_err[ii][0]**2))\n",
    "\n",
    "\n",
    "ax[1,0].set_xlabel(r'$cos(\\theta)$')\n",
    "ax[1,1].set_xlabel(r'$cos(\\theta)$')\n",
    "ax[1,2].set_xlabel(r'$cos(\\theta)$')\n",
    "ax[0,0].set_ylabel('N')\n",
    "ax[1,0].set_ylabel('N')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "print('ratio s opal',ratio_s_opal)\n",
    "print('ratio s opal error:', ratio_s_opal_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# apply s channel correction\n",
    "opalB_corr = np.zeros((7,4))\n",
    "ratio_s_opal[5] = ratio_s_opal[6] #s channel seperation does not work for data point 6, apply ratio of 7.\n",
    "opalB_corr[:,1:] = np.array(opalB)[:,1:]\n",
    "\n",
    "for ii in range(7):\n",
    "    opalB_corr[ii][0] = opalB[ii][0] * ratio_s_opal[ii] #Multiply with the fraction of s channels\n",
    "    opalB_err[ii][0] = np.sqrt(ratio_s_opal[ii]**2 * opalB_err[ii][0]**2 + opalB[ii][0]**2 * ratio_s_opal_err[ii]**2) #Error propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Calculate cross section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Optaining the cross sections using the Luminosities \n",
    "Sigma = [0] * 7\n",
    "Sigma_err = [0] * 7\n",
    "\n",
    "i = 0\n",
    "while i < 7:\n",
    "    # limi[i] is time integrated Luminosity\n",
    "    Sigma[i] = opalB_corr[i] / lumi[i]\n",
    "    Sigma_err[i] = [0] * 4\n",
    "    \n",
    "    # loop because opalB_err is list of arreys\n",
    "    k = 0\n",
    "    while k < 4:\n",
    "        # Gaussian error propagation\n",
    "        Sigma_err[i][k] = np.sqrt((1 / lumi[i])**2 * opalB_err[i][k]**2 + (opalB_corr[i][k] / lumi[i]**2)**2 * err_all_lumi[i]**2)\n",
    "        k += 1\n",
    "    Sigma_err[i] = np.array(Sigma_err[i])\n",
    "    i += 1\n",
    "\n",
    "# Printing all rescaled event counts\n",
    "tpye = ['ee', 'mm', 'tt', 'qq']\n",
    "for ii in range(4):\n",
    "    print('\\nSigma for {} events:'.format(tpye[ii]))\n",
    "    for jj in range(7):\n",
    "        print('Energy of LEP {} and Sigma = {:6.3f} +- {:4.3f}'.format(energy[jj], Sigma[jj][ii], Sigma_err[jj][ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# apply ratiation correction\n",
    "Sigma_corr = np.zeros((4,7))\n",
    "Sigma_corr_err = np.zeros((4,7))\n",
    "for ii in range(7):\n",
    "    Sigma_corr[0,ii] = Sigma[ii][0] + xs_corrections['leptonic'][ii] #Add radiation correction\n",
    "    Sigma_corr[1,ii] = Sigma[ii][1] + xs_corrections['leptonic'][ii]\n",
    "    Sigma_corr[2,ii] = Sigma[ii][2] + xs_corrections['leptonic'][ii]\n",
    "    Sigma_corr[3,ii] = Sigma[ii][3] + xs_corrections['hadronic'][ii]\n",
    "    Sigma_corr_err[0,ii] = Sigma_err[ii][0]\n",
    "    Sigma_corr_err[1,ii] = Sigma_err[ii][1]\n",
    "    Sigma_corr_err[2,ii] = Sigma_err[ii][2]\n",
    "    Sigma_corr_err[3,ii] = Sigma_err[ii][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Plot and fit of cross sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def relativistic_breit_wigner_normalized(x, resonance_mass, width, A):\n",
    "    '''Relativistic Breit-Wigner normalized to an amplitude of one\n",
    "    \n",
    "    The Relativistic Breit-Wigner function was modiefied to\n",
    "    scale the amplitude to one and use a parameter A, which describes\n",
    "    the Amplitude (i.e. the cross section at the rsonance energy).\n",
    "    \n",
    "    Args:\n",
    "        x (float): variable for the centre point energy\n",
    "        resonance_mass (float): parameter descibing the position\n",
    "        width (float): parameter descibing the width\n",
    "        A (float): parameter descibing the amplitude\n",
    "    '''\n",
    "    gamma = np.sqrt(resonance_mass**2 * (resonance_mass ** 2 + width ** 2))\n",
    "    k = 2.0 * np.sqrt(2) * resonance_mass * width * gamma / (np.pi * np.sqrt(resonance_mass ** 2 + gamma))\n",
    "    return A * (resonance_mass**2 * width**2/k) *k / ((x ** 2 - resonance_mass ** 2) ** 2 + resonance_mass ** 2 * width ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Fitting with the breit wegner function for electrons, muons, tauons and hadrons\n",
    "listE = np.linspace(energy[0],energy[-1],1000) #Energy axis for the plot\n",
    "bounds = [[90.0,0,1],[91.5,4,70]] #bounds for the fit\n",
    "p0 = [91.2,1,2] # start parameters\n",
    "coeff = np.zeros((4,3)) #dummy matrix for the coefficients\n",
    "\n",
    "#Apply curve fit\n",
    "coeff[0,:], var_matrix_e  = curve_fit(relativistic_breit_wigner_normalized, energy, Sigma_corr[0], sigma=Sigma_corr_err[0], absolute_sigma=True, p0 = p0, bounds = bounds)\n",
    "coeff[1,:], var_matrix_m  = curve_fit(relativistic_breit_wigner_normalized, energy, Sigma_corr[1], sigma=Sigma_corr_err[1], absolute_sigma=True, p0 = p0, bounds = bounds)\n",
    "coeff[2,:], var_matrix_t  = curve_fit(relativistic_breit_wigner_normalized, energy, Sigma_corr[2], sigma=Sigma_corr_err[2], absolute_sigma=True, p0 = p0, bounds = bounds)\n",
    "coeff[3,:], var_matrix_h  = curve_fit(relativistic_breit_wigner_normalized, energy, Sigma_corr[3], sigma=Sigma_corr_err[3], absolute_sigma=True, p0 = p0, bounds = bounds)\n",
    "\n",
    "fit_sigma = np.zeros((4,len(listE))) #Fitted sigmas for the plot\n",
    "chi = np.zeros(4) #Chis square\n",
    "for i in range(4):\n",
    "    fit_sigma[i,:] = relativistic_breit_wigner_normalized(listE, *coeff[i,:])\n",
    "    chi[i] = chi2(Sigma_corr[i],relativistic_breit_wigner_normalized(np.array(energy),*coeff[i,:]),Sigma_corr_err[i],ndf = 4)\n",
    "print('Coefficients: Position [GeV], Width [GeV], Amplitude [nb] \\n',coeff)\n",
    "print('Chisquare vaalues for electrons, muons tauons, hadrons:', chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Plotting the cross sections with the coresponding Breit-Wigner Fits\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "#fig.suptitle('Total crossection')\n",
    "ax[0,0].errorbar(energy, Sigma_corr[0], yerr=Sigma_corr_err[0], label = 'electrons', fmt='.', color='black', zorder=2)\n",
    "ax[0,1].errorbar(energy, Sigma_corr[1], yerr=Sigma_corr_err[1], label = 'muon', fmt='.', color='black', zorder=2)\n",
    "ax[1,0].errorbar(energy, Sigma_corr[2], yerr=Sigma_corr_err[2], label = 'tauon', fmt='.', color='black', zorder=2)\n",
    "ax[1,1].errorbar(energy, Sigma_corr[3], yerr=Sigma_corr_err[3], label = 'hadrons', fmt='.', color='black', zorder=2)\n",
    "\n",
    "ax[0,0].plot(listE,fit_sigma[0,:], color=colors['es'], zorder=1, label = 'Breit-Wiegner fit \\n $ \\chi ^2 / ndf $ = {:1.2}'.format(chi[0]) )\n",
    "ax[0,1].plot(listE,fit_sigma[1,:], color=colors['m'], zorder=1,label = 'Breit-Wiegner fit \\n $ \\chi ^2 / ndf $ = {:1.2}'.format(chi[1]) )\n",
    "ax[1,0].plot(listE,fit_sigma[2,:], color=colors['t'], zorder=1, label = 'Breit-Wiegner fit \\n $ \\chi ^2 / ndf $ = {:1.2}'.format(chi[2]) )\n",
    "ax[1,1].plot(listE,fit_sigma[3,:], color=colors['q'], zorder=1, label = 'Breit-Wiegner fit \\n $ \\chi ^2 / ndf $ = {:1.2}'.format(chi[3]) )\n",
    "\n",
    "ax[0,0].set_ylim(0,2.5)\n",
    "ax[0,0].title.set_text('Total corss section electrons')\n",
    "ax[0,0].title.set_size('17')\n",
    "\n",
    "ax[0,1].title.set_text('Total corss section muons')\n",
    "ax[0,1].title.set_size('17')\n",
    "ax[1,0].title.set_text('Total corss section tauons')\n",
    "ax[1,0].title.set_size('17')\n",
    "ax[1,1].title.set_text('Total corss section hadrons')\n",
    "ax[1,1].title.set_size('17')\n",
    "ax[0,0].legend()\n",
    "ax[0,1].legend()\n",
    "ax[1,0].legend()\n",
    "ax[1,1].legend()\n",
    "\n",
    "ax[1,1].set_xlabel('E [GeV]')\n",
    "ax[1,0].set_xlabel('E [GeV]')\n",
    "ax[0,0].set_ylabel(r'$\\sigma$ [nb]')\n",
    "ax[1,0].set_ylabel(r'$\\sigma$ [nb]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Theoretical crossection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Converting the ampltudes in nb into natural units (here MeV)\n",
    "sig_e_conv = coeff[0,2] * 0.00257 * 1e-9\n",
    "sig_m_conv = coeff[1,2] * 0.00257 * 1e-9\n",
    "sig_t_conv = coeff[2,2] * 0.00257 * 1e-9\n",
    "sig_h_conv = coeff[3,2] * 0.00257 * 1e-9\n",
    "\n",
    "# Calculating the partial width of the e events\n",
    "Gamma_e = np.sqrt(1/(12*np.pi) * sig_e_conv) * coeff[0,0]*1000 * coeff[0,1]*1000\n",
    "\n",
    "# Using the partial width of the e events to calculate the other partial widths\n",
    "Gamma_m = 1/(12*np.pi) * sig_m_conv * (coeff[1,0]*1000 * coeff[1,1]*1000)**2 / Gamma_e\n",
    "Gamma_t = 1/(12*np.pi) * sig_t_conv * (coeff[2,0]*1000 * coeff[2,1]*1000)**2 / Gamma_e\n",
    "Gamma_h = 1/(12*np.pi) * sig_h_conv * (coeff[3,0]*1000 * coeff[3,1]*1000)**2 / Gamma_e\n",
    "\n",
    "print('Partial width\\nGamma_e = {:3.2f}\\nGamma_m = {:3.2f}\\nGamma_t = {:3.2f}\\nGamma_q = {:3.2f}'.format(Gamma_e, Gamma_m, Gamma_t, Gamma_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Calculating the error on the partial widths\n",
    "# Covariance termes are taken in to account because of the corelations between the parameters of the fits.\n",
    "Gamma_e_err = np.sqrt((Gamma_e/coeff[0,0])**2 * var_matrix_e[0][0] + (Gamma_e/coeff[0,1])**2 * var_matrix_e[1][1] + (Gamma_e/coeff[0,2]/2)**2 * var_matrix_e[2][2] + 2*(Gamma_e/coeff[0,0])*(Gamma_e/coeff[0,1]) * var_matrix_e[1][0] + 2*(Gamma_e/coeff[0,0])*(Gamma_e/coeff[0,2]/2) * var_matrix_e[0][2] + 2*(Gamma_e/coeff[0,0])*(Gamma_e/coeff[0,0]) * var_matrix_e[1][0])\n",
    "\n",
    "Gamma_m_err = np.sqrt((2*Gamma_m/coeff[1,0])**2 * var_matrix_m[0][0] + (2*Gamma_m/coeff[1,1])**2 * var_matrix_m[1][1] + (Gamma_m/coeff[1,2])**2 * var_matrix_m[2][2] + 2*(2*Gamma_m/coeff[1,0])*(2*Gamma_m/coeff[1,1]) * var_matrix_m[1][0] + 2*(2*Gamma_m/coeff[1,0])*(Gamma_m/coeff[1,2]) * var_matrix_m[0][2] + 2*(2*Gamma_m/coeff[1,1])*(Gamma_m/coeff[1,2]) * var_matrix_m[1][2] + (Gamma_m/Gamma_e)**2 * Gamma_e_err**2)\n",
    "\n",
    "Gamma_t_err = np.sqrt((2*Gamma_t/coeff[2,0])**2 * var_matrix_t[0][0] + (2*Gamma_t/coeff[2,1])**2 * var_matrix_t[1][1] + (Gamma_t/coeff[2,2])**2 * var_matrix_t[2][2] + 2*(2*Gamma_t/coeff[2,0])*(2*Gamma_t/coeff[2,1]) * var_matrix_t[1][0] + 2*(2*Gamma_t/coeff[2,0])*(Gamma_t/coeff[2,2]) * var_matrix_t[2][0] + 2*(2*Gamma_t/coeff[2,1])*(Gamma_t/coeff[2,2]) * var_matrix_t[1][2] + (Gamma_t/Gamma_e)**2 * Gamma_e_err**2)\n",
    "\n",
    "Gamma_h_err = np.sqrt((2*Gamma_h/coeff[3,0])**2 * var_matrix_h[0][0] + (2*Gamma_h/coeff[3,1])**2 * var_matrix_h[1][1] + (Gamma_h/coeff[3,2])**2 * var_matrix_h[2][2] + 2*(2*Gamma_h/coeff[3,0])*(2*Gamma_h/coeff[3,1]) * var_matrix_h[1][0] + 2*(2*Gamma_h/coeff[3,0])*(Gamma_h/coeff[3,2]) * var_matrix_h[2][0] + 2*(2*Gamma_h/coeff[3,1])*(Gamma_h/coeff[3,2]) * var_matrix_h[1][2] + (Gamma_h/Gamma_e)**2 * Gamma_e_err**2)\n",
    "\n",
    "\n",
    "print('{:2.2f} {:2.2f} {:2.2f} {:2.2f}'.format(Gamma_e_err, Gamma_m_err, Gamma_t_err, Gamma_h_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Apply a weighted mean to get the width of Z^0\n",
    "Gamma_z_z = (coeff[0,1]/var_matrix_e[1][1]) + (coeff[1,1]/var_matrix_m[1][1]) + (coeff[2,1]/var_matrix_t[1][1]) + (coeff[3,1]/var_matrix_h[1][1])\n",
    "Gamma_z_n = (1/var_matrix_e[1][1]) + (1/var_matrix_m[1][1]) + (1/var_matrix_t[1][1]) + (1/var_matrix_h[1][1])\n",
    "\n",
    "Gamma_z = Gamma_z_z / Gamma_z_n * 1e3\n",
    "Gamma_z_err = 1/np.sqrt(Gamma_z_n) * 1e3\n",
    "\n",
    "\n",
    "print('Gamma_Z = ({:4.0f} +- {:2.0f}) MeV'.format(Gamma_z, Gamma_z_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Literature cross section\n",
    "Gamma_l_lit = 83.8\n",
    "Gamma_lit = 2.4952e3\n",
    "Gamma_h_lit = 1744\n",
    "Gamma_v_lit = 499\n",
    "Mz_lit = 91.1876e3\n",
    "Gamma_ve_lit = 167.6\n",
    "\n",
    "sigma_lit = 12*np.pi/Mz_lit**2*Gamma_l_lit*Gamma_l_lit/Gamma_lit**2/0.00257*1e9\n",
    "print(sigma_lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Neutrino Number\n",
    "\n",
    "# Subtracting the  partial widths measured from the optained total width and deviding by the width of a neutrion\n",
    "# The neutrino width is from literature (PDG)\n",
    "N_neutrino = (Gamma_z - Gamma_e - Gamma_m - Gamma_t - Gamma_h ) / Gamma_ve_lit\n",
    "Gamma_z_err = np.sqrt(var_matrix_e[1][1] + var_matrix_m[1][1] + var_matrix_t[1][1] + var_matrix_h[1][1])/4\n",
    "N_n_err = np.sqrt(Gamma_z_err**2+Gamma_e_err**2+Gamma_m_err**2+Gamma_t_err**2+Gamma_h_err**2)/Gamma_ve_lit\n",
    "\n",
    "print('Number of Neutrinos', N_neutrino, 'error:' ,N_n_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 3: Forward-backward asymmetry and $\\sin^2(\\theta_\\text{W})$ in muon final states\n",
    "\n",
    "* Using the **muon channel only**, measure the forward-backward asymmetry $\\mathcal{A}_\\text{FB}$ using OPAL data and muon Monte Carlo events. Take into account the radiation corrections given below. \n",
    "\n",
    "| $\\sqrt{s}$   \\[GeV\\]| Radiation correction [-]|  \n",
    "| --- | --- | \n",
    "| 88.47 | 0.021512  | \n",
    "| 89.46 | 0.019262  | \n",
    "| 90.22 | 0.016713  | \n",
    "| 91.22 | 0.018293  | \n",
    "| 91.97 | 0.030286  | \n",
    "| 92.96 | 0.062196  | \n",
    "| 93.76 | 0.093850  | \n",
    "\n",
    "Feel free to use the dictionary 'radiation_corrections' given below.\n",
    "\n",
    "* Measure the **Weinberg angle** as $\\sin^2(\\theta_\\text{W})$. Compare the measurement with the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "radiation_corrections = { 'energy' : [ 88.47, 89.46, 90.22, 91.22, 91.97, 92.96, 93.76] ,\n",
    "                          'correction' : [0.021512, 0.019262, 0.016713, 0.018293, 0.030286, 0.062196, 0.093850]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Calculating the Forward-Backward Asymmetry for muon data from OPAL\n",
    "opalMcutsUP = [0] * 7\n",
    "opalMcutsDOWN = [0] * 7\n",
    "AFB = [0] * 7\n",
    "AFB_err = [0] * 7\n",
    "\n",
    "i = 0\n",
    "while i < 7:\n",
    "    UP0 = branchesopal['cos_thet'] >= 0\n",
    "    UP1 = branchesopal['cos_thet'] <= .95\n",
    "    DOWN0 = branchesopal['cos_thet'] < 0\n",
    "    DOWN1 = branchesopal['cos_thet'] >= -.95\n",
    "    opalMcutsUP[i] = opalMcuts[i] & UP0 & UP1# Mask with all muon data with positiv cos_thet\n",
    "    opalMcutsDOWN[i] = opalMcuts[i] & DOWN0 & DOWN1# Mask with all muon data with negativ cos_thet\n",
    "    \n",
    "    # Sum over all positive (in cos_thet) data ponits\n",
    "    Np = np.sum(opalMcutsUP[i])\n",
    "    Np_err = np.sqrt(Np)\n",
    "    # Sum over all negativ (in cos_thet) data ponits\n",
    "    Nm = np.sum(opalMcutsDOWN[i])\n",
    "    Nm_err = np.sqrt(Nm)\n",
    "    \n",
    "    # Calculating the Asymmetry\n",
    "    AFB[i] = ((Np - Nm) / (Np + Nm)) + radiation_corrections['correction'][i]\n",
    "    \n",
    "    # Derivations of the Asymmetry for the Forward and Backward Numbers\n",
    "    dNp = (2*Nm / (Np + Nm)**2)\n",
    "    dNm = (2*Np / (Np + Nm)**2)\n",
    "    \n",
    "    # Gaussian Error probagation\n",
    "    AFB_err[i] = np.sqrt(Np_err**2 * dNp**2 + Nm_err**2 * dNm**2)\n",
    "    i += 1\n",
    "print(AFB)\n",
    "print(AFB_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def Lin(x,a,b):\n",
    "    '''Linear Function\n",
    "    \n",
    "    Linear function used to Fit the Forward-Backward Asymmetry.\n",
    "    \n",
    "    Args:\n",
    "        x (float): variable for the centre point energy\n",
    "        a (float): parameter describing the slope\n",
    "        b (float): parameter describing the axes intersection\n",
    "    '''\n",
    "    return ((a*x) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Do a linear fit through the Forward-Backward Asymmetry at diffent energies in order to detirmain the Asymmetry at the resonance\n",
    "LinParam, LinCovar = curve_fit(Lin, energy, AFB, sigma=AFB_err, absolute_sigma=True)\n",
    "\n",
    "\n",
    "AFB_resonance = Lin(coeff[1,0], *LinParam)# reading the linear fit at the resonance\n",
    "# Calculating the derivations of the Fit function for the parameters and the resonance energy\n",
    "chi_AFB = chi2(AFB, Lin(np.array(energy),*LinParam),np.array(AFB_err), 7-2)\n",
    "\n",
    "dE = LinParam[0]\n",
    "da = coeff[1,0]\n",
    "db = 1\n",
    "# Using the derivations to calculate the error of the Asymmetry at resonance.\n",
    "# The parameters of the fit are corelated, therefor the covariance between them is takn in to acount.\n",
    "AFB_resonance_err = np.sqrt(dE**2 * var_matrix_m[0][0] + da**2 * LinCovar[0][0] + db**2 * LinCovar[1][1] + 2 * da * db * LinCovar[0][1])\n",
    "\n",
    "print(r'A_FB = ',' ({:4.3f} +- {:4.3f})'.format(AFB_resonance, AFB_resonance_err))\n",
    "print('Fit chi^2/ndf', chi_AFB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Ploting the Asymmetry at diffent energies with the linear Fit\n",
    "plt.style.use(mplhep.style.ATLAS)\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.errorbar(energy, AFB, yerr=AFB_err, zorder=2, label = r'$A_{FB}$ at diffrent beam energies', color='black', fmt=\".\")# r'$A_{FB}$ at diffrent beam energies'\n",
    "x = np.linspace(88, 94, 2)\n",
    "plt.plot(x, Lin(x, *LinParam), zorder=1, label='linear Fit \\n $ \\chi^2/ndf$ = {:1.2}'.format(chi_AFB), color=colors['m'])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Forward-Backward Asymmetry')\n",
    "plt.xlabel('Energy of the Lep beam')\n",
    "plt.ylabel(r'$A_{FB}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Using the Asymmetry at the resonance to calculate the Weinberg angle\n",
    "Weinberg = 1/4 * (1-np.sqrt(abs(AFB_resonance)/3))\n",
    "Weinberg_err = np.sqrt((-np.sqrt(1/3) / (8 * np.sqrt(abs(AFB_resonance))))**2 * (AFB_resonance_err)**2)\n",
    "\n",
    "print('({:4.4f} +- {:4.4f})'.format(Weinberg, Weinberg_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Calculating the Forward-Backward Asymmetry for muon MC data\n",
    "UP0 = brancheses[1]['cos_thet'] >=0\n",
    "UP1 = brancheses[1]['cos_thet'] <= .95#1\n",
    "DOWN0 = brancheses[1]['cos_thet'] < 0\n",
    "DOWN1 = brancheses[1]['cos_thet'] >= -.95#-1\n",
    "MC_McutsUP = UP0 & UP1\n",
    "MC_McutsDOWN = DOWN0 & DOWN1\n",
    "\n",
    "Np = np.sum(MC_McutsUP)\n",
    "Np_err = np.sqrt(Np)\n",
    "Nm = np.sum(MC_McutsDOWN)\n",
    "Nm_err = np.sqrt(Nm)\n",
    "\n",
    "MC_AFB = ((Np - Nm) / (Np + Nm)) + radiation_corrections['correction'][3]\n",
    "\n",
    "dNp = (2*Nm / (Np + Nm)**2)\n",
    "dNm = (2*Np / (Np + Nm)**2)\n",
    "\n",
    "MC_AFB_err = np.sqrt(Np_err**2 * dNp**2 + Nm_err**2 * dNm**2)\n",
    "\n",
    "print(MC_AFB)\n",
    "print(MC_AFB_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# Calculating the Weinberg angle for MC data\n",
    "MC_Weinberg = 1/4 * (1-np.sqrt(MC_AFB/3))\n",
    "MC_Weinberg_err = np.sqrt((-np.sqrt(1/3)/(8 * np.sqrt(MC_AFB)))**2 * (MC_AFB_err)**2)\n",
    "print(MC_Weinberg, MC_Weinberg_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 4: Tests on lepton universality¶\n",
    "\n",
    "* Test the lepton universality from the total cross sectinos on the peak for $Z\\to e^+ e^-$, $Z\\to \\mu^+ \\mu^-$ and $Z\\to \\tau^+ \\tau^-$ events. What is the ratio of the total cross section of the hadronic channel to the leptonic channels on the peak? Compare with the ratios obtained from the branching rations and discuss possible differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Comparing the cross sections for the leptons\n",
    "print('Sigma')\n",
    "print('{:4.3f} +- {:4.3f}'.format(coeff[0,2], np.sqrt(var_matrix_e[2,2])))\n",
    "print('{:4.3f} +- {:4.3f}'.format(coeff[1,2], np.sqrt(var_matrix_m[2,2])))\n",
    "print('{:4.3f} +- {:4.3f}\\n'.format(coeff[2,2], np.sqrt(var_matrix_t[2,2])))\n",
    "\n",
    "\n",
    "# Comparing the ratios of the cross sections for the leptons to the cross section of the hadrons\n",
    "E_ratio = coeff[0,2] / coeff[3,2]\n",
    "M_ratio = coeff[1,2] / coeff[3,2]\n",
    "T_ratio = coeff[2,2] / coeff[3,2]\n",
    "\n",
    "E_ratio_err = np.sqrt((1/coeff[3,2])**2 * (var_matrix_e[2,2])**2 + (-coeff[0,2]/coeff[3,2]**2)**2 * (var_matrix_h[2,2])**2)\n",
    "M_ratio_err = np.sqrt((1/coeff[3,2])**2 * (var_matrix_m[2,2])**2 + (-coeff[1,2]/coeff[3,2]**2)**2 * (var_matrix_h[2,2])**2)\n",
    "T_ratio_err = np.sqrt((1/coeff[3,2])**2 * (var_matrix_h[2,2])**2 + (-coeff[2,2]/coeff[3,2]**2)**2 * (var_matrix_h[2,2])**2)\n",
    "\n",
    "print('Sigma ratio')\n",
    "print('{:5.5f} +- {:5.5f}'.format(E_ratio, E_ratio_err))\n",
    "print('{:5.5f} +- {:5.5f}'.format(M_ratio, M_ratio_err))\n",
    "print('{:5.5f} +- {:5.5f}\\n'.format(T_ratio, T_ratio_err))\n",
    "\n",
    "# Comparing the ratios of the partial widths of the leptons to the width of the hadrons\n",
    "E_ratio_branch = Gamma_e / Gamma_h\n",
    "M_ratio_branch = Gamma_m / Gamma_h\n",
    "T_ratio_branch = Gamma_t / Gamma_h\n",
    "\n",
    "E_ratio_branch_err = np.sqrt((1/Gamma_h)**2 * Gamma_e_err**2 + (Gamma_e/Gamma_h**2)**2 * Gamma_h_err**2)\n",
    "M_ratio_branch_err = np.sqrt((1/Gamma_h)**2 * Gamma_m_err**2 + (Gamma_m/Gamma_h**2)**2 * Gamma_h_err**2)\n",
    "T_ratio_branch_err = np.sqrt((1/Gamma_h)**2 * Gamma_t_err**2 + (Gamma_t/Gamma_h**2)**2 * Gamma_h_err**2)\n",
    "\n",
    "print('Branching')\n",
    "print('{:4.4f} +- {:4.4f}'.format(E_ratio_branch, E_ratio_branch_err))\n",
    "print('{:4.4f} +- {:4.4f}'.format(M_ratio_branch, M_ratio_branch_err))\n",
    "print('{:4.4f} +- {:4.4f}'.format(T_ratio_branch, T_ratio_branch_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Grope Data\n",
    "The data sown below was obtained from the Grope data set and was used for a initial depiction of the different variables resulting from different types of fermions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "G_runs = [0] * 5\n",
    "G_events = [0] * 5\n",
    "G_eleps = [0] * 5\n",
    "G_nchares = [0] * 5\n",
    "G_pchares = [0] * 5\n",
    "G_eecals = [0] * 5\n",
    "G_ehcals = [0] * 5\n",
    "\n",
    "fs = ['ee', 'mm', 'tt', 'qq']\n",
    "\n",
    "j = 0\n",
    "while j < 4:\n",
    "    eefile = open('opal_data/grope/'+fs[j]+'_ex.txt').read()\n",
    "    eefile = eefile.split('\\n')\n",
    "\n",
    "    N = len(eefile) - 1\n",
    "\n",
    "    e_run = [0] * N\n",
    "    e_event = [0] * N\n",
    "    e_elep = [0] * N\n",
    "    e_nchare = [0] * N\n",
    "    e_pchare = [0] * N\n",
    "    e_eecal = [0] * N\n",
    "    e_ehcal = [0] * N\n",
    "\n",
    "    for i in range(1,N):\n",
    "        if j == 0:\n",
    "            line = eefile[i].split('\\t')\n",
    "            e_run[i] = float(line[0])\n",
    "            e_event[i] = float(line[1])\n",
    "            e_elep[i] = float(line[2])\n",
    "            e_nchare[i] = float(line[3])\n",
    "            e_pchare[i] = float(line[4])\n",
    "            e_eecal[i] = float(line[6])\n",
    "            e_ehcal[i] = float(line[8])\n",
    "        else:\n",
    "            line = eefile[i].split('\\t')\n",
    "            e_run[i] = float(line[0])\n",
    "            e_event[i] =float(line[1])\n",
    "            e_elep[i] = float(line[2])\n",
    "            e_nchare[i] = float(line[3])\n",
    "            \n",
    "            try:\n",
    "                e_pchare[i] = float(line[4])\n",
    "            except:\n",
    "                e_pchare[i] = 0\n",
    "            try:\n",
    "                e_eecal[i] = float(line[5])\n",
    "            except:\n",
    "                e_eecal[i] = 0\n",
    "            e_ehcal[i] = float(line[6])\n",
    "    \n",
    "    G_runs[j] = e_run\n",
    "    G_events[j] = e_event\n",
    "    G_eleps[j] = e_elep\n",
    "    G_nchares[j] = e_nchare\n",
    "    G_pchares[j] = e_pchare\n",
    "    G_eecals[j] = e_eecal\n",
    "    G_ehcals[j] = e_ehcal\n",
    "    \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS)\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(G_nchares[0], bins=25, range=(0.,100.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='ee', zorder=2)\n",
    "bin_content, bin_edges, _ = plt.hist(G_nchares[1], bins=25, range=(0.,100.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='mm', zorder=3)\n",
    "bin_content, bin_edges, _ = plt.hist(G_nchares[2], bins=25, range=(0.,100.), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='tt', zorder=4)\n",
    "bin_content, bin_edges, _ = plt.hist(G_nchares[3], bins=25, range=(0.,100.), histtype='step',  linewidth=2, edgecolor=colors\n",
    "\n",
    "\n",
    "['q'], hatch='/', label='qq', zorder=5)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Grope Data: charged tracks')\n",
    "plt.xlim(0.,50)\n",
    "plt.ylim(0,1e2)\n",
    "plt.xlabel('Ncharged')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS)\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(G_pchares[0], bins=20, range=(0.,150.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='ee')\n",
    "bin_content, bin_edges, _ = plt.hist(G_pchares[1], bins=20, range=(0.,150.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='mm')\n",
    "bin_content, bin_edges, _ = plt.hist(G_pchares[2], bins=20, range=(0.,150.), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='tt')\n",
    "bin_content, bin_edges, _ = plt.hist(G_pchares[3], bins=20, range=(0.,150.), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='qq')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Grope Data: Total track momenta')\n",
    "plt.xlim(-5,150.)\n",
    "plt.ylim(0,4e1)\n",
    "plt.xlabel('$p_{track}$')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS)\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(G_eecals[0], bins=25, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='e')\n",
    "bin_content, bin_edges, _ = plt.hist(G_eecals[1], bins=25, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='m')\n",
    "bin_content, bin_edges, _ = plt.hist(G_eecals[2], bins=25, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='t')\n",
    "bin_content, bin_edges, _ = plt.hist(G_eecals[3], bins=25, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='q')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Grope Data: Energy in electronic calorimeter')\n",
    "plt.xlim(0.,150.)\n",
    "plt.ylim(0,.6e2)\n",
    "plt.xlabel('$E_{ecal}$')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.style.use(mplhep.style.ATLAS)\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "bin_content, bin_edges, _ = plt.hist(G_ehcals[0], bins=15, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['e'], hatch='/', label='e')\n",
    "bin_content, bin_edges, _ = plt.hist(G_ehcals[1], bins=15, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['m'], hatch='/', label='m')\n",
    "bin_content, bin_edges, _ = plt.hist(G_ehcals[2], bins=15, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['t'], hatch='/', label='t')\n",
    "bin_content, bin_edges, _ = plt.hist(G_ehcals[3], bins=15, range=(0.,200.), histtype='step',  linewidth=2, edgecolor=colors['q'], hatch='/', label='q')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Grope Data: energy in hadronic calorimeter')\n",
    "plt.xlim(0.,120)\n",
    "plt.ylim(0,.6e2)\n",
    "plt.xlabel('$E_{hcal}$')\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3-ubuntu",
   "resource_dir": "/usr/local/share/jupyter/kernels/python3-ubuntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}